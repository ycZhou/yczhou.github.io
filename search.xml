<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[可能是最全的机器学习框架搭建手册]]></title>
      <url>%2F2017%2F03%2F28%2F%E5%8F%AF%E8%83%BD%E6%98%AF%E6%9C%80%E5%85%A8%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E6%89%8B%E5%86%8C%2F</url>
      <content type="text"><![CDATA[写这篇博客是应朋友的需求。最开始，由于时间限制，只会有基于Ubuntu的手册，其他Linux发行版本暂且搁置一下。如果大家在配置的过程中遇到了我没有提到的问题，欢迎大家在下方留言，我们一同解决问题。 同时，我并没有直接把所有需要安装的依赖一次性列出来，就是希望大家能够在拿到一个新的软件来编译时，也能自己一步一步解决所遇到的问题。多使用Google吧，它绝对会是你今后的好伙伴。也不要怕报错出现了一大堆英文，仔细读一读，你就能找到你需要检索的东西。 Ubuntu在这里将会提到如何在Ubuntu 16.04.2（全新安装）上配置各类机器学习框架。 由于系统是全新安装的，所以，我们先安装上必要的工具： 1sudo apt install vim git build-essential Caffe首先我们按照Caffe的官方安装指导Caffe | Installation: Ubuntu来配置Caffe，途中遇到问题在阐述具体的解决方案。 依赖安装首先大家看到的是两条终端命令（暂时不要运行）： 12sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compliersudo apt-get install --no-install-recommends libboost-all-dev 由于使用apt-get安装软件十分的粗暴，我们这里需要OpenCV支持CUDA，所以我们通过源代码编译安装OpenCV。那么这里又引出一个问题，那就是如何在Ubuntu 16.04上安装Nvidia官方驱动以及CUDA。 Nvidia驱动以及CUDA在Ubuntu 16.04上安装Nvidia私有驱动没有之前版本那样复杂，我们通过apt就能十分方便的安装。 首先，将第三方开源驱动nouveau屏蔽（这一步非常重要） 用vim打开 1sudo vim /etc/modprobe.d/blacklist.conf 在末尾添加如下几行： 12345blacklist vga16fbblacklist nouveaublacklist rivafbblacklist rivatvblacklist nvidiafb 然后在终端中运行： 1sudo apt install nvidia-367 nvidia-modprobe nvidia-prime 当然，如果你使用的机器CPU没有集成显卡，nvidia-prime可以不用安装。安装完成后重启，在应用程序NVIDIA X Server Setting中有一个PRIME Profiles，在其中选择NVIDIA(Performance Mode)就可以使用你的独立显卡了（由于我是在工作站上配置的，没有集成显卡，所以这一步也没办法截图给大家看）。 接下来，我们开始配置CUDA，进入CUDA的下载地址CUDA 8.0 Downloads | NVIDIA Developer，Operating System选择Linux，接着选中x86_64，然后选择Ubuntu，版本选中16.04，Installer Type选择runfile(local)，下方便会显示出下载，点击下载即可。完成后，在终端中运行 1234#先将工作目录切换到刚才下载的文件所在的目录中，这里使用默认的Downloads文件夹作为示范cd ~/Downloadschmod +x cuda_8.0.61_375.26_linux.runsudo sh cuda_8.0.61_375.26_linux.run 然后出现了冗长的License Agreement，放心吧，你绝对不会有心情去认真看的，所以狂按space键吧，到底后，它会问你 12Do you accept the previously read EULA?accept/decline/quit: 废话，我们要使用CUDA当然得同意，毫不犹豫输入accept然后敲回车 12Install NVIDIA accelerated Graphics Driver for Linux-x86_64 375.26?(y)es/(n)o/(q)uit: 由于我们之前已经安装过驱动了，这里选择n 12Install CUDA 8.0 Toolkit?(y)es/(n)o/(q)uit: 这里选择y 12Enter Toolkit Locationdefault is /usr/local/cuda-8.0: 直接回车 12Do you want to install a symbolic link at /usr/local/cuda?(y)es/(n)o/(q)uit: 选择y 12Install the CUDA 8.0 Samples?(y)es/(n)o/(q)uit: 选择y 12Enter CUDA Samples Locationdefault is /home/ignatius: 直接回车，然后CUDA就开始安装了，完成后，我们来配置环境变量： 1234echo &apos;export CUDA_PATH=/usr/local/cuda&apos; &gt;&gt; ~/.bashrcecho &apos;export PATH=$PATH:$CUDA_PATH/bin&apos; &gt;&gt; ~/.bashrcecho &apos;export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CUDA_PATH/lib:$CUDA_PATH/lib64&apos; &gt;&gt; ~/.bashrcsource ~/.bashrc 接着，我们进入CUDA Samples目录开始测试CUDA安装是否成功： 1234cd ~/NVIDIA_CUDA-8.0_Samplesmake all -j40cd bin/x86_64/linux/release/./deviceQuery 这里会输出一大堆关于你的显卡的信息，其实我们想要的只是最后一行： 1Result = PASS 如果看到了这一行，证明CUDA已经配置成功了，否则，仔细检查一下上面有哪一步你没做对。到这里我们还要配置cuDNN (NVIDIA CUDA Deep Neural Network library)，下载链接NVIDIA cuDNN | NVIDIA Developer。下载cuDNN需要注册英伟达的开发者账号，用邮箱几分钟就完成了。然后选择合适的版本，我这里选择的是cuDNN v5.1, for CUDA8.0, for Linux （之所以没有选择最新的v6.0是因为6.0在Caffe编译时会出错）。 1234cd ~/Downloadstar -zxvf cudnn-8.0-linux-x64-v5.1.tgzsudo cp lib64* /usr/local/cuda/lib64sudo cp cudnn* /usr/local/cuda/inculde 编译OpenCV首先安装依赖： 1sudo apt install checkinstall cmake pkg-config yasm libtiff5-dev libjpeg-dev libjasper-dev libavcodec-dev libavformat-dev libswscale-dev libdc1394-22-dev libxine2-dev libv4l-dev python-dev python-numpy libtbb-dev libqt4-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils 从GitHub克隆OpenCV： 1git clone https://github.com/opencv/opencv.git 编译并安装OpenCV 12345cd opencvmkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON -D ENABLE_FAST_MATH=1 -D WITH_CUBLAS=1 ..make all -j40 到make的时候可以去喝杯咖啡再来，这一步需要的时间比较长，编译完成后使用如下命令安装： 1sudo make install 接下来配置环境变量： 1234echo &apos;/usr/local/lib&apos; | sudo tee -a /etc/ld.so.conf.d/opencv.confsudo ldconfigecho &apos;export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig&apos; &gt;&gt; ~/.bashrcexec -l $SHELL 查看OpenCV版本： 1pkg-config --modversion opencv 这样OpenCV就安装完成了。下面我们开始配置Caffe。 接着讲上面的依赖安装，这个时候我们不需要libopencv-dev了，于是我们执行： 12sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compliersudo apt-get install --no-install-recommends libboost-all-dev 按照官网的提示，已经可以进行编译了，不过我们首先需要从GitHub上克隆Caffe的源码： 1git clone https://github.com/BVLC/caffe.git 然后，我们开始编译，首先要修改一下Makefile： 123cd caffecp Makefile.config.example Makefile.configvim Makefile.config 这里我只列出有改动的地方： 1234USE_CUDNN := 1OPENCV_VERSION := 3BLAS := openWITH_PYTHON_LAYER := 1 然后开始编译： 1make -j40 这个时候，出现了一个下图所示的错误： 这是由于没有安装gflags造成的，在前面提到的依赖安装中，官网的说明并不完全，现在我们补上： 1sudo apt install libgflags-dev libgoogle-glog-dev liblmdb-dev libopenblas-dev 再make试试，发现又出现错误了： 好吧，我们再补上一个库： 1sudo apt install libblas-dev 再次尝试编译，发现还是有错误: 我们在之前已经安装过libhdf5-serial-dev，这里之所以报错是因为从Ubuntu 16.04开始文件包含的位置发生了变化，我们找到 12INCLUDE_DIRS := $(PYTHON_INCLUDE) ／usr/local/includeLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib 将它们改为： ``shellINCLUDE_DIRS := $(PYTHON_INCLUDE) ／usr/local/include /usr/include/hdf5/serialLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial123456至于我是如何知道hdf5.h的目录的，当然是通过find命令或者locate命令来查找。重新编译，这一次成功了，接着我们能开始：```shellmake test -j40make runtest 不出意外的话，所有的都能通过，接下来编译Python wrapper： 1make pycaffe 接下来将caffe目录添加到PYTHONPATH： 1echo &apos;export PYTHONPATH=$PYTHONPATH:$HOME/caffe/python&apos; &gt;&gt; .bashrc 在python中尝试import caffe，发现了如下图所示的错误： 我们通过apt来安装skimage： 1sudo apt install python-skimage 再次尝试import caffe，又出现了 ImportError: No module named google.protobuf.internal，我们再次通过apt来安装： 1sudo apt install python-protobuf 再次尝试，发现成功了，到这里Caffe的配置就算完成了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[鸢尾花分类及sklearn实现]]></title>
      <url>%2F2016%2F08%2F04%2F%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB%E5%8F%8Asklearn%E5%AE%9E%E7%8E%B0%2F</url>
      <content type="text"><![CDATA[背景介绍前一段时间在学校数学建模培训的课程上给大家讲了神经网络的相关内容，由于准备时间比较紧张，后面的案例分析部分讲得也不是很详细，这里给大家讲一讲鸢尾花分类相关的东西。上次将鸢尾花分类的代码（神经网络，Matlab）代码给了大家，这里我主要是用Python写的。至于为什么要用Python，我这里就不再赘述了。之前已经给大家讲过如何用神经网络实现分类，这里我主要是想给大家看看机器学期的其他算法。鸢尾花数据是一个简易有趣的数据集。这个数据集来源于科学家在一岛上找到一种花的三种不同亚类别，分别叫做setosa,versicolor,virginica。但是这三个种类并不是很好分辩，所以他们又从花萼长度，花萼宽度，花瓣长度，花瓣宽度这四个角度测量不同的种类用于定量分析。基于这四个特征，这些数据成了一个多重变量分析的数据集。下面，我们就利用sklearn试着从不同的角度去分析一下这个数据集。在我篇博文“The Beginning of Machine Learning | 机器学习初步“中有介绍如何在CentOS 6.5中配置sklearn，可以给大家作为参考。由于目前不怎么在Windows上做开发，也就没写如何在Windows上配置，有需要的可以参考目前最全的windows平台下：scikit-learn安装教程。 方法一：k-均值聚类给定鸢尾花数据集，如果我们知道这有三种鸢尾花，但是无法得到它们的标签，我们可以尝试非监督学习：我们可以通过某些标准聚类观测值到几个组别里。 导入数据集我们先导入sklearn中的鸢尾花数据集： 123from sklearn import datasetsiris = datasets.load_iris() 数据存储在.data项中，是一个(n_samples, n_features)数组。 1iris.data.shape (150, 4) 每个观察对象的种类存贮在数据集的.target属性中。这是一个长度为n_samples的整数一维数组: 1iris.target.shape (150,) 我们再来绘图看看： 12345678910111213141516import numpy as npimport matplotlibimport matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3D%matplotlib inlineplt.xkcd()fig1 = plt.figure(1)ax = fig1.gca(projection='3d')ax.scatter(iris.data[:,3],iris.data[:,0],iris.data[:,2])ax.set_xlabel('Petal width')ax.set_ylabel('Sepal length')ax.set_zlabel('Petal length')ax.set_title("Iris Data")fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5) 第一种思路是这样:这三种不同的品种每一种想必都会有特点或者存在一定的相似性。我们不妨先把这些杂乱无章的数据分成三类，然后对应的标出他们每一类的类别。如果按照这样的想法，那么这一个问题就变成了一个聚类问题。作为聚类问题，我们可以用KMeans算法去解决。有关于KMeans大家可以参考博文：KMeans 可以直观的看出来，图中把点分成了三类。然后我们做出这样一种假设：每一类有一个中心点，这一类的绝大部分点到中心点的距离应该是小于到其他类中心点的距离的。之所以说绝大部分是因为考虑到点的特例，我们不能因为单独的几个点而否定之前的大部分。基于这一个思想我们可以确定所要优化的目标函数，我们假设分类N个数据到K个类别，则有：其中的rnk意味着归类到k时为1，剩下为0.剩下的具体如何优化这里不在详细说了。 K-means Demo：我们来看看sklearn官网的一个用KMeans聚类鸢尾花的demo： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071print(__doc__)# Code source: Gaël Varoquaux# Modified for documentation by Jaques Grobler# License: BSD 3 clausefrom sklearn.cluster import KMeans# 固定随机数种子，使每次运行结果一致np.random.seed(5)centers = [[1, 1], [-1, -1], [1, -1]]iris = datasets.load_iris()X = iris.datay = iris.target# 这里一共实例化了三个预测器estimators = &#123;'k_means_iris_3': KMeans(n_clusters=3), 'k_means_iris_8': KMeans(n_clusters=8), 'k_means_iris_bad_init': KMeans(n_clusters=3, n_init=1, init='random')&#125;fignum = 1for name, est in estimators.items(): fig = plt.figure(fignum, figsize=(4, 3)) plt.clf() ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134) plt.cla() est.fit(X) labels = est.labels_ ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float)) ax.w_xaxis.set_ticklabels([]) ax.w_yaxis.set_ticklabels([]) ax.w_zaxis.set_ticklabels([]) ax.set_xlabel('Petal width') ax.set_ylabel('Sepal length') ax.set_zlabel('Petal length') fig = matplotlib.pyplot.gcf() fig.set_size_inches(18.5, 10.5) fignum = fignum + 1# Plot the ground truthfig = plt.figure(fignum, figsize=(4, 3))plt.clf()ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)plt.cla()for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]: ax.text3D(X[y == label, 3].mean(), X[y == label, 0].mean() + 1.5, X[y == label, 2].mean(), name, horizontalalignment='center', bbox=dict(alpha=.5, edgecolor='w', facecolor='w')) # 设置画布尺寸fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5)# Reorder the labels to have colors matching the cluster resultsy = np.choose(y, [1, 2, 0]).astype(np.float)ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=y)ax.w_xaxis.set_ticklabels([])ax.w_yaxis.set_ticklabels([])ax.w_zaxis.set_ticklabels([])ax.set_xlabel('Petal width')ax.set_ylabel('Sepal length')ax.set_zlabel('Petal length') Automatically created module for IPython interactive environment &lt;matplotlib.text.Text at 0x1130a6910&gt; skleran.cluster.KMeans 详解不要觉得上面代码很复杂，我们来分解看看。导入数据前文中已经说过了，这里不再赘述。我们这里使用了sklearn中的KMeans类，首先： 1from sklearn.cluster import KMeans 然后我们来实例化一个预测器，由背景知识我们知道，鸢尾花有三类，所以我们设置n_cluster=3： 1estimator = KMeans(n_clusters=3, n_init=1,init='random') 下面来给大家详细介绍一下KMeans的参数（这里我会翻译sklearn中关于KMeans的文档，之后用到的不再翻译）： class sklearn.cluster.KMeans(n_clusters=8, init=’k-means++’, n_init=10, max_iter=300, tol=0.0001, precompute_distances=’auto’, verbose=0, random_state=None, copy_x=True, n_jobs=1) 参数： n_clusters : 整型, 可选的, 默认值: 8 聚类中心的数量 max_iter : 整型, 默认值: 300 K-means算法的最大迭代次数。 n_init : 整型, 默认值: 10 最后K均值聚类的结果还与初始聚类中心有关，n_init设为10意味着进行10次随机初始化，选择效果最好的一种来作为模型。 init : {‘k-means++’, ‘random’ 或者一个n维数组} 初始化方法, 默认为 ‘k-means++’: ‘k-means++’ : 用一个智能的方法选择K-means算法的初始聚类中心以加快收敛。 ‘random’: 从数据中随机选择k行作为初始聚类中心。 如果传入的是一个n维数组，它应形如 (n_clusters, n_features) 并且给定初始聚类中心。 precompute_distances : {‘auto’, True, False} 距离预计算 (更快但是也意味着更大的内存消耗). ‘auto’ : 不进行距离预计算如果 n_samples * n_clusters &gt; 12 million. 这相当于对于双精度来说，每个事务将多消耗100MB的内存。 True : 总是进行距离预计算。 False : 从不进行距离预计算。 tol : 浮点型, 默认值: 1e-4 相对误差 n_jobs : 整型 同时进行运算的事务数。 如果是-1，CPU的所有核心都将用于运算。如果是1，则只进行单线程运算，一般只用于debug。对于 n_jobs 小于 -1, (n_cpus + 1 + n_jobs) 个核心将被使用。比如说对于 n_jobs = -2, 只有一个核心将不被使用。 random_state : 整数或者 numpy.RandomState, 可选的 如果给定一个整数，那么久相当于固定随机数种子。默认使用numpy的随机数生成器。 verbose : 整型, 默认值：0 冗长模式。 copy_x : 布尔值, 默认值：True 如果copy_x为True，则原始数据不会被修改。如果为False，原来的数据被修改。 属性： clustercenters ：数组，形如[n_clusters, n_features] 聚类中心的坐标。 labels_ : : 每个数据点的标签。 inertia_ : 浮点型 数据点到最近的聚类中心的距离的和。 方法： fit(X[, y]) 把数据输入到分类器里，即训练模型。 fit_predict(X[, y]) 计算聚类中心并用分类器对未知数据进行分类。 fit_transform(X[, y]) 计算聚类中心并将X变换到cluster-distance空间。 get_params([deep]) 获取估计器的参数。 predict(X) 预测X所属的最近的聚类中心。 score(X[, y]) set_params(**params) 设置估计器的参数。 transform(X[, y]) 将X变换到cluster-distance空间。 更多具体的请参考sklearn.cluster.KMeans 那我们现在来进行聚类： 1estimator.fit(X) KMeans(copy_x=True, init=&apos;random&apos;, max_iter=300, n_clusters=3, n_init=1, n_jobs=1, precompute_distances=&apos;auto&apos;, random_state=None, tol=0.0001, verbose=0) 来看看聚类中心： 123ecc = estimator.cluster_centers_print eccecc.shape [[ 6.85384615 3.07692308 5.71538462 2.05384615] [ 5.88360656 2.74098361 4.38852459 1.43442623] [ 5.006 3.418 1.464 0.244 ]] (3, 4) 我们再来看看分类后的标签： 123labels = estimator.labels_print labelslabels.shape [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1] (150,) 好，下面我们来看看聚类后的结果： 123456789101112131415161718192021fig1 = plt.figure(1)plt.clf()ax = Axes3D(fig1, rect=[0, 0, .95, 1], elev=48, azim=134)ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=labels.astype(np.float))ax.scatter(ecc[:,3], ecc[:,0], ecc[:,2], s=200) # 绘制聚类中心ax.w_xaxis.set_ticklabels([])ax.w_yaxis.set_ticklabels([])ax.w_zaxis.set_ticklabels([])ax.set_xlabel('Petal width')ax.set_ylabel('Sepal length')ax.set_zlabel('Petal length')fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5)for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]: ax.text3D(X[y == label, 3].mean(), X[y == label, 0].mean() + 1.5, X[y == label, 2].mean(), name, horizontalalignment='center', bbox=dict(alpha=.5, edgecolor='w', facecolor='w')) 这样呢，我们就将数据集中的150株鸢尾花分为了三类。 假设说我现在新测量了一株鸢尾花的数据，那么我们可以使用KMeans的predict方法得到它属于哪一类鸢尾花： 12rs = estimator.predict([[ 5.0, 3.6, 1.3, 0.25]])print "The label is : %d" % rs[0] The label is : 2 方法二：k最近邻（kNN）最简单的可能的分类器是最近邻：给定一个新的观测值，将n维空间中最靠近它的训练样本标签给它。其中n是每个样本中特性(features)数。 k最近邻分类器内部使用基于球树(ball tree)来代表它训练的样本。 knn示例这里我们使用sklearn中的KNeighborsClassifier类 12from sklearn.neighbors import KNeighborsClassifierknn = KNeighborsClassifier(n_neighbors=3) 同样的KNeighborsClassifier类也具有fit方法： 1knn.fit(iris.data, iris.target) KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=1, n_neighbors=3, p=2, weights=&apos;uniform&apos;) 好了，我们将kNN分类器训练完成了，下面就可以用我们训练好的分类器来进行预测： 1print "The label is: %d" % knn.predict([[0.1, 0.2, 0.3, 0.4]]) The label is: 0 训练集和测试集当验证学习算法时，不要用一个用来拟合估计器的数据来验证估计器的预测非常重要。确实，通过kNN估计器，我们将总是获得关于训练集完美的预测。 1234perm = np.random.permutation(iris.target.size)X = X[perm]y = y[perm]knn.fit(X[:100], y[:100]) KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=1, n_neighbors=3, p=2, weights=&apos;uniform&apos;) 1knn.score(X[100:], y[100:]) 0.93999999999999995 方法三：主成分分析（PCA）与支持向量机（SVM）主成分分析PCA不仅在可视化高维数据集时非常有用。它可以用来作为帮助加速对高维数据不那么有效率的监督方法的预处理步骤。 123from sklearn.decomposition import PCApca = PCA(n_components=2)pca.fit(iris.data) PCA(copy=True, n_components=2, whiten=False) 现在我们来对鸢尾花数据集进行主成分分析并可视化降维后的数据： 123456import pylab as plX = pca.transform(iris.data)pl.scatter(X[:, 0], X[:, 1], c=iris.target)fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5) 支持向量机SVM尝试构建一个两个类别的最大间隔超平面。它选择输入的子集，调用支持向量即离分离的超平面最近的样本点。 sklearn中有好几种支持向量机实现。最普遍使用的是svm.SVC，svm.NuSVC和svm.LinearSVC;“SVC”代表支持向量分类器(Support Vector Classifier)(也存在回归SVMs，在sklearn中叫作“SVR”)。 核函数类别不总是可以用超平面分离，所以人们指望有些可能是多项式或指数实例的非线性决策函数： 线性核 svc = svm.SVC(kernel=’linear’) 多项式核 svc = svm.SVC(kernel=’poly’, … degree=3) # degree: polynomial degree RBF核(径向基函数) svc = svm.SVC(kernel=’rbf’) # gamma: inverse of size of # radial kernel SVM示例线性核函数1234from sklearn import svmclf = svm.SVC(kernel='linear')clf.fit(X, iris.target) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 一旦我们已经从数据学习，我们可以使用我们的模型来预测未观测数据最可能的结果 1print "The label is: %d" % clf.predict([[ 5.0, 3.6]]) The label is: 2 我们来看看SVM作出的决策边界： 123456789101112xmin,xmax = X[:,0].min()-0.1, X[:,0].max()+0.1ymin,ymax = X[:,1].min()-0.1, X[:,1].max()+0.1xx,yy = np.meshgrid(np.arange(xmin,xmax,0.01),np.arange(ymin,ymax,0.01))zgrid = np.c_[xx.ravel(),yy.ravel()]yp = clf.predict(zgrid)ig3 = plt.figure(3)plot1 = plt.pcolormesh(xx,yy,yp.reshape(xx.shape))plot2 = plt.scatter(X[:,0],X[:,1],c=iris.target,s=60)plt.xlim(xmin,xmax)plt.ylim(ymin,ymax)fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5) 多项式核1234567891011121314clf = svm.SVC(kernel='poly', degree=3)clf.fit(X, iris.target)xmin,xmax = X[:,0].min()-0.1, X[:,0].max()+0.1ymin,ymax = X[:,1].min()-0.1, X[:,1].max()+0.1xx,yy = np.meshgrid(np.arange(xmin,xmax,0.01),np.arange(ymin,ymax,0.01))zgrid = np.c_[xx.ravel(),yy.ravel()]yp = clf.predict(zgrid)ig3 = plt.figure(4)plot1 = plt.pcolormesh(xx,yy,yp.reshape(xx.shape))plot2 = plt.scatter(X[:,0],X[:,1],c=iris.target,s=60)plt.xlim(xmin,xmax)plt.ylim(ymin,ymax)fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5) rbf核1234567891011121314clf = svm.SVC(kernel='rbf')clf.fit(X, iris.target)xmin,xmax = X[:,0].min()-0.1, X[:,0].max()+0.1ymin,ymax = X[:,1].min()-0.1, X[:,1].max()+0.1xx,yy = np.meshgrid(np.arange(xmin,xmax,0.01),np.arange(ymin,ymax,0.01))zgrid = np.c_[xx.ravel(),yy.ravel()]yp = clf.predict(zgrid)ig3 = plt.figure(4)plot1 = plt.pcolormesh(xx,yy,yp.reshape(xx.shape))plot2 = plt.scatter(X[:,0],X[:,1],c=iris.target,s=60)plt.xlim(xmin,xmax)plt.ylim(ymin,ymax)fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[The Beginning of Machine Learning | 机器学习初步]]></title>
      <url>%2F2016%2F07%2F13%2Fml%2F</url>
      <content type="text"><![CDATA[什么是机器学习 ？当今时代，不论文理，不论农医，各行各业的人士，都或多或少听说过机器学习这个词。 一个故事说明什么是机器学习&emsp;&emsp;时至如今，机器学习所涵盖的范围已经太广太广，这个词让很多人非常的疑惑。首先，它是英文Machine Learning(ML)的直译，在计算机界Machine一般指计算机。 &emsp;&emsp;传统上如果我们想让计算机工作，我们给它一串指令，然后它遵循这一串指令一步步执行下去。有因有果，非常明确。在机器学习中，它接受你输入的数据。也就是说，机器学习是一种让计算机利用数据而不是指令来进行工作的方法。这听起来非常不可思议，但结果上却是非常可行的。“统计”思想将在你学习“机器学习”相关理念时无时无刻不伴随着你，相关而不是因果的概念将是支撑机器学习能够工作的核心概念。&emsp;&emsp;这个例子来源于我真实的生活经验，我在思考这个问题的时候突然发现它的过程可以被扩充化为一个完整的机器学习过程，因此我决定将这个例子作为所有介绍的开始。这个故事我将之称为“等人问题”。 &emsp;&emsp;我相信大家都有跟别人相约，然后等人的经历。现实生活中不是每个人都是那么守时的，于是当你碰到一些爱迟到的人，你的时间不可避免的要浪费。现在我就给大家举这样一个例子。 &emsp;&emsp;我有一个朋友A，他不是那么的守时，最常见的表现是他经常迟到。当有一次我跟他约好3点钟在某个麦当劳见面时，在我出门的那么一刻，我突然意识到一个问题：我现在出发合适吗？我会不会又到了地点后，花上数十分钟去等他？我决定采取一个策略来解决这个问题。 &emsp;&emsp;想要解决这个问题，有好几种方法。第一种方法是采用知识：我搜寻能够解决这个问题的知识。但是非常遗憾，没有人会把如何等人这个问题作为知识传授，因此我不可能找到已有的知识能够解决这个问题。第二种方法就是询问他人：我去询问他人以获得解决这个问题的能力。但是同样，这个问题可能没有人能够解答，因为可能没人碰上和我一样的情况。第三种方法就是准则法：我问自己，我是否设立过什么准则去面对这个问题？例如，无论别人如何，我都会守时到达。但我不是这一样一个死板的人，我没有设立过这样的规则。 &emsp;&emsp;实际上，我相信有种方法比以上三种都要合适。我把过往跟A相约的经历全部回想一遍，发现跟他相约的次数中，迟到站了大多数的比例。而我利用这来预测他这次迟到的可能性。如果这个值超出了我心目中的某个界限，那我选择等一会儿再出发。假设我与A约过5次，他迟到的次数是4次，准时1次，那么他迟到的比例是80%，假如说我心中的阈值是70%，那我就选择等一等再出发。假如说他按时到达5次，迟到1次，那么他迟到的比例是20%，低于我心中的阈值，那我选择按时出门。这个方法又被称为经验法。在经验法的思考中，我实际上利用了以往所有相约的数据。因此也可以称之为依据数据做的判断。 &emsp;&emsp;依据数据所做的判断跟机器学习的思想根本上是一致的 &emsp;&emsp;在刚才的思考过程中，我们只考虑了“频次”这种属性。在真实的机器学习中，这可能都算不上一个应用。一般的机器学习模型至少考虑两个量：一个是因变量，也就是我们希望预测的结果，在这个例子中就是A迟到与否。另一个是因变量，也就是用来A是否迟到的量。假设我们将时间作为自变量，譬如我发现A所有迟到的日子基本都是星期五，而在非星期五的情况下他基本上不迟到，于是我就可以建立一个模型，来模拟A迟到与否跟日子是否是星期五的概率。如下图： &emsp;&emsp;图中所展示的就是一个决策树模型。 &emsp;&emsp;当我们考虑的变量只有一个时，情况较为简单。如果把我们的自变量再增加一个，例如A迟到的部分情况是在他开车过来的时候（你可以认为他开车的水平比较烂，或者是路上有些堵）。于是我们可以关联考虑这些信息，建立一个更为复杂的模型，这个模型就包含了两个自变量和一个因变量。 &emsp;&emsp;再考虑复杂一些的情况，A迟到与否跟天气也有一定的关联，例如在下雨的时候，A迟到的次数更多。那么这时候我们就需要考虑三个自变量了。 &emsp;&emsp;如果我们希望能够预测A迟到的具体时间，那么我们可以把他每次迟到的时间跟前面考虑的自变量统一建立一个模型。于是通过这个模型，我们就能预测他大概会迟到几分钟。这样就可以帮助我们更好的规划我们出门的时间。在这样的情况下，决策树就无法很好的支撑了，因为决策树只能预测离散的数据。现在我们尝试使用线性回归的方法来建立这个模型。 &emsp;&emsp;如果我把建立模型的过程交给电脑，比如把所有的自变量和因变量输入，然后让计算机帮我们生成一个模型，同时让计算机根据我当前的情况，给出我是否需要推迟出门时间，需要推迟几分钟的建议。那么计算机执行这些辅助决策的过程就是机器学习的过程。 &emsp;&emsp;机器学习方法是计算机利用已有的数据（经验），得出了某种模型（迟到的规律），并利用此模型预测未来（是否迟到）的一种方法。 &emsp;&emsp;接下来，我会开始对机器学习做正式的介绍，包括定义、范围、方法和应用等等。 机器学习的定义： A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E. (From Wikipedia) 假设用P来评估计算机程序在某任务类T上的性能，若一个程序通过利用经验E在T中任务上获得了性能改善，则我们就说关于T和P，改程序对E进行了学习。 &emsp;&emsp;从广义上来说，机器学习是一种能够赋予机器“学习”的能力以此让它能够完成直接编程无法完成的功能的方法。但从实践的意义上来说，机器学习就是一种通过利用数据，训练出模型，然后使用模型预测的一种方法。 &emsp;&emsp;举个例子，就拿很多人关心的房子来说。假如现在我手中有一套住房需要售卖，我应该给它标上多少的价格？房子的面积是100平方米，价格应该是100万，120万还是180万？ &emsp;&emsp;很显然，我希望获得房价与面积的某种规律。那么我该如何获得这个规律？用报纸上的房价平均数据？还是参考别人面积相似的房子？无论哪种，似乎都不太靠谱。 &emsp;&emsp;我现在希望获得一个合理的，并且能够最大程度的反映面积与房价关系的规律。于是我调查了周围与我房型类似的一些房子，获得了一组数据。这组数据中包含了大大小小房子的面积和价格，如果我能从这组数据中找出面积雨价格的规律，那么我就可以得出我的房子的价格。 &emsp;&emsp;这个规律的寻找很简单，拟合出一条直线，让它“穿过”所有的点，并且与各个点的距离尽可能的小。通过这条直线，我获得了一个能够最佳反映房价与面积的规律。这条直线同时也是式子y=a•x+b所表明的规律。a、b是直线的参数，获得这些参数以后，我们就能计算出房子的价格。假设a=0.75，b=50，则房价=100•0.75+50=125（万）。这个结果与前文提到的100万，120万，180万都不一样。由于这条直线综合考虑了大部分的情况，因此从“统计”意义上来说，这是一个最合理的预测。 &emsp;&emsp;在求解过程中透露出了两个信息： &emsp;&emsp;1. 房价模型是根据拟合的函数类型决定的。如果是直线，那么拟合出的就是直线方程。如果是其他类型的线，例如抛物线，那么拟合出的就是抛物线方程。机器学习有众多算法，一些强力算法可以拟合出复杂的非线性模型，用来反映一些不适直线所能表的的情况。 &emsp;&emsp;2. 如果我们的数据（这里说的数据是指的有用的数据）越多，我们的模型也就越能够考虑到更多的情况，这样对于新情况的预测效果可能就会越好。这是机器学习中“数据为王”思想的一个体现。一般来说（不是绝对），数据越多，最后机器学习声称的模型预测能力也就越强。 &emsp;&emsp;通过我们拟合直线的过程，我们可以对机器学习过程做一个简单的回顾：首先，我们需要在计算机中存储历史的数据。接着，我们将这些数据通过机器学习算法进行处理，这个过程在机器学习中被称为“训练”，处理的结果可以被我们用来对新的数据进行预测，这个结果一般被称为模型。对新的数据的预测过程在机器学习中叫做“预测”。”训练“与”预测“是机器学习的两个过程，”模型“则是过程中间输出的结果，”训练“产生”模型“，”模型“指导”预测“。 &emsp;&emsp;下图展示了机器学习的过程与人类对历史经验归纳过程的对比 &emsp;&emsp;人类在成长、生活的过程中积累了很多的历史与经验。人类定期地对这些经验进行“归纳”，获得了生活的“规律”。当人类遇到未知的问题或者需要对未来进行“推测”的时候，人类使用这些“规律”，对未知的问题与未来进行“推测”，从而指导自得的生活和工作。 &emsp;&emsp;机器学习中的“训练”和“归纳”和“推测”过程。通过这样的对应，我们可以发现，机器学习的思想其实并不复杂，仅仅是对人类生活中学习成长过程的一个模拟。由于机器学习不是基于传统意义上编程行程的结果，因此它的处理过程不是因果的逻辑，而是通过归纳思想得出的相关性理论。 机器学习的算法&emsp;&emsp;通过上面的介绍我们大致了解了机器学习，在这个部分我会简单介绍一下机器学习中的经典代表算法。这部分介绍的重点是这些方法的内涵思想，数学与实践细节不会在这讨论。 1.回归算法 &emsp;&emsp;在大部分机器学习的课程中，回归算法都是介绍的第一个算法。原因有两个：一是回归算法比较简单，介绍它可以让人平滑地从统计学迁移到机器学习中；二是回归算法是后面若干算法的基石，如果不理解回归算法，则无法学习这些算法。回归算法有两个重要的子类：线性回归和逻辑回归。 &emsp;&emsp;线性回归就是我们前面说到过的房价求解问题。如何拟合出一条直线最佳匹配我们所有的数据？一般使用“最小二乘法”来求解。“最小二乘法”的思想是这样的，假设我们拟合出的直线代表的数据是真实值，而观测到的数据代表拥有误差的值。为了尽可能减小误差的影响，需要求解一条直线使得所有误差的平方和最小。这就是一个典型的优化问题，常用的求解方法有最速下降法和牛顿法等。最速下降法是解决回归模型中最简单而且有效的方法之一。从严格意义上来说，由于后文中的神经网络中有线性回归的因子，因此最速下降法在后面的算法实现中也有应用。 &emsp;&emsp;逻辑回归是一种与线性回归非常相似的算法，但是，从本质上讲，线性回归处理的问题类型与逻辑回归不一致。线性回归处理的是连续问题，而逻辑回归属于分类算法，也就是说，逻辑回归预测的结果是离散的分类，例如判断邮件是否是垃圾邮件等。实现方面，逻辑回归只是对线性回归的计算结果加上了一个Sigmoid函数，将数值结果转化为了0到1之间的概率，下面的图像中给出了一些Sigmoid函数的图形： &emsp;&emsp;接着我们根据这个概率可以做预测，例如概率大于0.5，则这封邮件邮件就是垃圾邮件，或者判断肿瘤是否为恶性肿瘤等。从直观上来说，逻辑回归是画出了一条分类线，见下图所示： &emsp;&emsp;假设我们有一组肿瘤患者的数据，这些患者的肿瘤中有些是良性的，假设为图中蓝色的圆圈，有些是恶性的，假设为图中的红色五角星。这里肿瘤的红色（五角星）和蓝色（圆圈）可以称为数据的“标签”。同时每个数据包括两个“特征”：患者的年龄与肿瘤的大小。我们将这两个特征与标签映射到这个二维空间上，形成了上图所示的数据。 &emsp;&emsp;当我有一个黄色的点时，我该如何判断这个肿瘤是恶性的还是良性的？根据红蓝点我们训练出了一个逻辑回归模型，也就是图中的分类线。这时，根据黄点出现在分类线的右侧，我们判断这个数据点的标签是红色，也就是这个肿瘤属于恶性肿瘤。 &emsp;&emsp;逻辑回归算法划出的分类线基本都是线性的(也有划出非线性分类线的逻辑回归，不过那样的模型在处理数据量较大的时候效率会很低)，这意味着当两类之间的界线不是线性时，逻辑回归的表达能力就不足。下面的两个算法是机器学习界最强大且重要的算法，都可以拟合出非线性的分类线。 2.神经网络 &emsp;&emsp;神经网络(也称之为人工神经网络，ANN)算法是80年代机器学习界非常流行的算法，不过在90年代中途衰落。现在，携着“深度学习”之势，神经网络重装归来，重新成为最强大的机器学习算法之一。 &emsp;&emsp;神经网络的诞生起源于对大脑工作机理的研究。早期生物界学者们使用神经网络来模拟大脑。机器学习的学者们使用神经网络进行机器学习的实验，发现在视觉与语音的识别上效果都相当好。在BP算法(加速神经网络训练过程的数值算法)诞生以后，神经网络的发展进入了一个热潮。BP算法的发明人之一是前面介绍的机器学习大牛Geoffrey Hinton。 &emsp;&emsp;具体说来，神经网络的学习机理是什么？简单来说，就是分解与整合。在著名的Hubel-Wiesel试验中，学者们研究猫的视觉分析机理是这样的。 &emsp;&emsp;比方说，一个正方形，分解为四个折线进入视觉处理的下一层中。四个神经元分别处理一个折线。每个折线再继续被分解为两条直线，每条直线再被分解为黑白两个面。于是，一个复杂的图像变成了大量的细节进入神经元，神经元处理以后再进行整合，最后得出了看到的是正方形的结论。这就是大脑视觉识别的机理，也是神经网络工作的机理。 &emsp;&emsp;神经网络的具体形式我将在后文中给大家讲解。 &emsp;&emsp;以图像识别为例，图像的原始输入是像素，相邻像素组成线条，多个线条组成纹理，进一步形成图案，图案构成了物体的局部，直至整个物体的样子。不难发现，可以找到原始输入和浅层特征之间的联系，再通过中层特征，一步一步获得和高层特征的联系。 &emsp;&emsp;下图会演示神经网络在图像识别领域的一个著名应用，这个程序叫做LeNet，是一个基于多个隐层构建的神经网络。通过LeNet可以识别多种手写数字，并且达到很高的识别精度与拥有较好的鲁棒性。 想要了解更多关于LeNet相关的知识请点击：Convolutional Neural Networks (LeNet)以及Deep Learning（深度学习）学习笔记整理系列。使用Caffe的读者可以看看Training LeNet on MNIST with Caffe。 &emsp;&emsp;进入90年代，神经网络的发展进入了一个瓶颈期。其主要原因是尽管有BP算法的加速，神经网络的训练过程仍然很困难。因此90年代后期支持向量机(Supported Vector Machine, SVM)算法取代了神经网络的地位。 3.支持向量机 &emsp;&emsp;支持向量机算法是诞生于统计学习界，同时在机器学习界大放光彩的经典算法。 &emsp;&emsp;支持向量机算法从某种意义上来说是逻辑回归算法的强化：通过给予逻辑回归算法更严格的优化条件，支持向量机算法可以获得比逻辑回归更好的分类界线。但是如果没有某类函数技术，则支持向量机算法最多算是一种更好的线性分类技术。 &emsp;&emsp;但是，通过跟高斯“核”的结合，支持向量机可以表达出非常复杂的分类界线，从而达成很好的的分类效果。“核”事实上就是一种特殊的函数，最典型的特征就是可以将低维的空间映射到高维的空间。 &emsp;&emsp;例如下图所示： &emsp;&emsp;我们如何在二维平面划分出一个圆形的分类界线？在二维平面可能会很困难，但是通过“核”可以将二维空间映射到三维空间，然后使用一个线性平面就可以达成类似效果。也就是说，二维平面划分出的非线性分类界线可以等价于三维平面的线性分类界线。于是，我们可以通过在三维空间中进行简单的线性划分就可以达到在二维平面中的非线性划分效果。 &emsp;&emsp;支持向量机是一种数学成分很浓的机器学习算法（相对的，神经网络则有生物科学成分）。在算法的核心步骤中，有一步证明，即将数据从低维映射到高维不会带来最后计算复杂性的提升。于是，通过支持向量机算法，既可以保持计算效率，又可以获得非常好的分类效果。因此支持向量机在90年代后期一直占据着机器学习中最核心的地位，基本取代了神经网络算法。直到现在神经网络借着深度学习重新兴起，两者之间才又发生了微妙的平衡转变。 4.聚类算法 &emsp;&emsp;前面的算法中的一个显著特征就是我的训练数据中包含了标签，训练出的模型可以对其他未知数据预测标签。在下面的算法中，训练数据都是不含标签的，而算法的目的则是通过训练，推测出这些数据的标签。这类算法有一个统称，即无监督算法(前面有标签的数据的算法则是有监督算法)。无监督算法中最典型的代表就是聚类算法。 &emsp;&emsp;让我们还是拿一个二维的数据来说，某一个数据包含两个特征。我希望通过聚类算法，给他们中不同的种类打上标签，我该怎么做呢？简单来说，聚类算法就是计算种群中的距离，根据距离的远近将数据划分为多个族群。 &emsp;&emsp;聚类算法中最典型的代表就是K-Means算法。 5.降维算法 &emsp;&emsp;降维算法也是一种无监督学习算法，其主要特征是将数据从高维降低到低维层次。在这里，维度其实表示的是数据的特征量的大小，例如，房价包含房子的长、宽、面积与房间数量四个特征，也就是维度为4维的数据。可以看出来，长与宽事实上与面积表示的信息重叠了，例如面积=长 × 宽。通过降维算法我们就可以去除冗余信息，将特征减少为面积与房间数量两个特征，即从4维的数据压缩到2维。于是我们将数据从高维降低到低维，不仅利于表示，同时在计算上也能带来加速。 &emsp;&emsp;刚才说的降维过程中减少的维度属于肉眼可视的层次，同时压缩也不会带来信息的损失(因为信息冗余了)。如果肉眼不可视，或者没有冗余的特征，降维算法也能工作，不过这样会带来一些信息的损失。但是，降维算法可以从数学上证明，从高维压缩到的低维中最大程度地保留了数据的信息。因此，使用降维算法仍然有很多的好处。 &emsp;&emsp;降维算法的主要作用是压缩数据与提升机器学习其他算法的效率。通过降维算法，可以将具有几千个特征的数据压缩至若干个特征。另外，降维算法的另一个好处是数据的可视化，例如将5维的数据压缩至2维，然后可以用二维平面来可视。降维算法的主要代表是PCA算法(即主成分分析算法)。 6.推荐算法 &emsp;&emsp;推荐算法是目前业界非常火的一种算法，在电商界，如亚马逊，天猫，京东等得到了广泛的运用。推荐算法的主要特征就是可以自动向用户推荐他们最感兴趣的东西，从而增加购买率，提升效益。推荐算法有两个主要的类别： &emsp;&emsp;一类是基于物品内容的推荐，是将与用户购买的内容近似的物品推荐给用户，这样的前提是每个物品都得有若干个标签，因此才可以找出与用户购买物品类似的物品，这样推荐的好处是关联程度较大，但是由于每个物品都需要贴标签，因此工作量较大。 &emsp;&emsp;另一类是基于用户相似度的推荐，则是将与目标用户兴趣相同的其他用户购买的东西推荐给目标用户，例如小A历史上买了物品B和C，经过算法分析，发现另一个与小A近似的用户小D购买了物品E，于是将物品E推荐给小A。 &emsp;&emsp;两类推荐都有各自的优缺点，在一般的电商应用中，一般是两类混合使用。推荐算法中最有名的算法就是协同过滤算法。 7.其它 &emsp;&emsp;除了以上算法之外，机器学习界还有其他的如高斯判别，朴素贝叶斯，决策树等等算法。但是上面列的六个算法是使用最多，影响最广，种类最全的典型。机器学习界的一个特色就是算法众多，发展百花齐放。 &emsp;&emsp;下面做一个总结，按照训练的数据有无标签，可以将上面算法分为监督学习算法和无监督学习算法，但推荐算法较为特殊，既不属于监督学习，也不属于非监督学习，是单独的一类。 监督学习算法： 线性回归，逻辑回归，神经网络，SVM 无监督学习算法： 聚类算法，降维算法 特殊算法： 推荐算法 &emsp;&emsp;除了这些算法以外，有一些算法的名字在机器学习领域中也经常出现。但他们本身并不算是一个机器学习算法，而是为了解决某个子问题。其中的代表有：最速下降法，主要运用在线型回归，逻辑回归，神经网络，推荐算法中；牛顿法，主要运用在线型回归中；BP算法，主要运用在神经网络中；SMO算法，主要运用在SVM中。 环境搭建(CentOS 6.5)Anaconda2-4.0.0.0 + scikit-learn + Theano 首先安装pyenv（Python版本控制器） 1234567$ yum -y install git gcc gcc-c++$ cd ~$ git clone https://github.com/yyuu/pyenv.git ~/.pyenv$ echo &apos;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&apos;&gt;&gt; ~/.bashrc$ echo &apos;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&apos;&gt;&gt; ~/.bashrc$ echo &apos;eval &quot;$(pyenv init -)&quot;&apos; &gt;&gt; ~/.bashrc$ exec $SHELL -l Anaconda2-4.0.0.0安装： 12$ pyenv install anaconda2-4.0.0.0$ pyenv global acanconda2-4.0.0.0 scikit-learn安装： 1$ conda install scikit-learn pip安装： 12$ wget https://bootstrap.pypa.io/get-pip.py$ python get-pip.py Theano安装： 1$ pip install theano 测试Theano： 12import theanotheano.test() 会显示theano的版本号，安装位置，已经其他包的安装版本，如numpy, nose, python等 从头开始实现神经网络：入门&emsp;&emsp;这里我不会推导所有的数学公式，在这我们会从头实现一个简单的两层神经网络。我会给我们正在做的事情一个相对直观的解释，也会给大家列出研读所需的资源链接。⚠️注意：这里的代码并不是高效的，只是为了让我们理解结构 产生数据集&emsp;&emsp;scikit-learn提供了一些很有用的数据集产生器，这部分我们就不用自己写代码了。这里我们使用sklearn.datasets.make_moons。 123456789101112import matplotlibimport numpy as npfrom sklearn import datasetsimport matplotlib.pyplot as plt%matplotlib inlinenp.random.seed(0)# 固定随机数种子，确保每次运行产生相同的随机数X, y = datasets.make_moons(300, noise=0.2)plt.xkcd()plt.scatter(X[:, 0], X[:, 1], s=60, c=y, cmap=plt.cm.Spectral)fig = matplotlib.pyplot.gcf()fig.set_size_inches(18.5, 10.5) &emsp;&emsp;产生的数据共有两类，分别用红点和蓝点表示。我们的目标就是，在给定x和y轴的情况下训练机器学习分类器以预测正确的分类。明显的，这些数据并不是线性可分的，我们不能通过简单的画一条直线来区分这两类数据。所以我们不能使用诸如Logistic回归之类的线性分类器来区分这两类数据。 Logistic回归&emsp;&emsp;为了证明上述的观点，我们来训练一个Logistic回归分类器。输入为坐标值，输出为分类（0或者1）。方便起见，这里使用scikit-learn库中的Logistic回归类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import matplotlibimport numpy as npfrom sklearn import datasets, linear_modelimport matplotlib.pyplot as plt%matplotlib inlinedef generate_data(): np.random.seed(0) X, y = datasets.make_moons(300, noise=0.2) return X, ydef visualize(X, y, clf): plot_decision_boundary(lambda x: clf.predict(x), X, y) plt.title("Logistic Regression") fig = matplotlib.pyplot.gcf() fig.set_size_inches(18.5, 10.5)def plot_decision_boundary(pred_func, X, y): x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 h = 0.01 xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) # 预测整个坐标平面中点的类别 Z = pred_func(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral) plt.scatter(X[:, 0], X[:, 1], s=60, c=y, cmap=plt.cm.Spectral)# plt.show()def classify(X, y): clf = linear_model.LogisticRegressionCV() clf.fit(X, y) return clfdef main(): X, y = generate_data() # visualize(X, y) clf = classify(X, y) visualize(X, y, clf)if __name__ == "__main__": main() &emsp;&emsp;图中展示了用Logistic回归分类器学习到的决策边界，使用一条直线尽量将数据分离开来。 神经网络浅讲神经元引子&emsp;&emsp;对于神经元的研究由来已久，20世纪初生物学家就已经知晓了神经元的组成结构。 &emsp;&emsp;一个神经元通常具有多个树突，主要用来接受传入信息；每个神经元只有一条轴突，轴突尾端有许多轴突末梢可以给其他多个神经元传递信息。轴突末梢跟其他神经元的树突相连，这个连接的部位在生物学上称为突触。 &emsp;&emsp;1943年，心理学家MuCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型（MP），下面我们会具体来了解神经元模型。 结构&emsp;&emsp;神经元模型是一个包含输入、计算和输出功能的模型。输入可以类比为神经元的树突，计算可以类比为细胞核，输出则可以类比为神经元的轴突。 &emsp;&emsp;下图是一个典型的神经元模型：包含3个输入，2个计算功能和一个输出。注意输入与求和之间的箭头，它们被称为“连接”，每个“连接”上有一个对应的“权值”。 &emsp;&emsp;对于更一般的情形，神经元模型的结构可以由下图给出： &emsp;&emsp;一个神经网络的训练算法就是让权重的值调整到最佳，以使得整个网络的预测效果最好。 &emsp;&emsp;我们使用a来表示输入，w来表示权值。一个表示连接的有向箭头可以这样来理解：在初端，传递的信号大小是a，端中间有加权参数w，经过这个加权后的信号就变成a*w，因此在连接的末端，信号的大小就变成了a*w。如果我们将神经元图中的所有变量用符号表示，并且写出输出的公式的话，就得到了了如下图所示的模型： &emsp;&emsp;可见z是在输入和权值的线性加权和叠加了一个函数g的值。在MP模型中，函数g就是sgn函数，也就是取符号函数，当输入大于0时，输出1，否则输出0。在以后的过程中，为了方便表述，我们将神经元的所有计算放在一个圆圈中。 &emsp;&emsp;当我们用“神经元”组成网络后，描述网络中的某个“神经元”时，我们更多地会用“单元”(unit)来指代，同时，由于神经网络的表现形式是一个有向图，有时也会用“结点”(node)来表达相同的意思。 &emsp;&emsp;神经元模型的使用可以这样理解： &emsp;&emsp;我们有一个数据，称之为样本。样本有四个属性，其中三个属性已知，一个属性未知。我们需要做的就是通过三个已知属性预测未知属性。 &emsp;&emsp;具体办法就是使用神经元的公式进行计算。三个已知属性的值是a1，a2，a3，未知属性的值是z。z可以通过公式计算出来。 &emsp;&emsp;这里，已知的属性称之为特征，未知的属性称之为目标。假设特征与目标之间确实是线性关系，并且我们已经得到表示这个关系的权值w1，w2，w3。那么，我们就可以通过神经元模型预测新样本的目标。 &emsp;&emsp;1943年发布的MP模型，虽然简单，但已经建立了神经网络大厦的地基。但是，MP模型中，权重的值都是预先设置的，因此不能学习。 &emsp;&emsp;1949年心理学家Hebb提出了Hebb学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。 &emsp;&emsp;尽管神经元模型与Hebb学习律都已诞生，但限于当时的计算机能力，直到接近十年后，第一个真正意义的神经网络才诞生。 单层神经网络（感知器）引子&emsp;&emsp;1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字–“感知器”（Perceptron）（有的文献翻译成“感知机”，下文统一用“感知器”来指代）。 &emsp;&emsp;感知器是当时首个可以学习的人工神经网络。Rosenblatt现场演示了其学习识别简单图像的过程，在当时的社会引起了轰动。 &emsp;&emsp;人们认为已经发现了智能的奥秘，许多学者和科研机构纷纷投入到神经网络的研究中。美国军方大力资助了神经网络的研究，并认为神经网络比“原子弹工程”更重要。这段时间直到1969年才结束，这个时期可以看作神经网络的第一次高潮。 结构&emsp;&emsp;下面来说明感知器模型。在原来MP模型的“输入”位置添加神经元节点，标志其为“输入单元”。其余不变，于是我们就有了下图： &emsp;&emsp;在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。 &emsp;&emsp;我们把需要计算的层次称之为“计算层”，并把拥有一个计算层的网络称之为“单层神经网络”。有一些文献会按照网络拥有的层数来命名，例如把“感知器”称为两层神经网络。但在本文里，我们根据计算层的数量来命名。 &emsp;&emsp;假如我们要预测的目标不再是一个值，而是一个向量，例如[2,3]。那么可以在输出层再增加一个“输出单元”。 &emsp;&emsp;下图显示了带有两个输出单元的单层神经网络，其中输出单元z1的计算公式如下图： &emsp;&emsp;可以看到，z1的计算跟原先的z并没有区别。我们已知一个神经元的输出可以向多个神经元传递，因此z2的计算公式如下图： &emsp;&emsp;可以看到，z2的计算中除了三个新的权值：w4，w5，w6以外，其他与z1是一样的。整个网络的输出如下图： &emsp;&emsp;我们改用二维的下标，用wx,y来表达一个权值。下标中的x代表后一层神经元的序号，而y代表前一层神经元的序号（序号的顺序从上到下）。例如，w1,2代表后一层的第1个神经元与前一层的第2个神经元的连接的权值（这种标记方式参照了Andrew Ng的课件）。根据以上方法标记，我们有了下图： &emsp;&emsp;如果我们仔细看输出的计算公式，会发现这两个公式就是线性代数方程组。因此可以用矩阵乘法来表达这两个公式。 &emsp;&emsp;例如，输入的变量是[a1，a2，a3]T，用向量a来表示。方程的左边是[z1，z2]T，用向量z来表示。系数则是矩阵W（2行3列的矩阵，排列形式与公式中的一样）。于是，输出公式可以改写成：z = g(W • a)。 &emsp;&emsp;这个公式就是神经网络中从前一层计算后一层的矩阵运算。 应用&emsp;&emsp;与神经元模型不同，感知器中的权值是通过训练得到的。因此，根据以前的知识我们知道，感知器类似一个逻辑回归模型，可以做线性分类任务。 &emsp;&emsp;我们可以用决策分界来形象的表达分类的效果。决策分界就是在二维的数据平面中划出一条直线，当数据的维度是3维的时候，就是划出一个平面，当数据的维度是n维时，就是划出一个n-1维的超平面。在二维的情形中，就类似于我们前文提到的肿瘤的良性与恶性判断。 &emsp;&emsp;感知器只能做简单的线性分类任务。但是当时的人们热情太过于高涨，并没有人清醒的认识到这点。于是，当人工智能领域的巨擘Minsky指出这点时，事态就发生了变化。Minsky在1969年出版了一本叫《Perceptron》的书，里面用详细的数学证明了感知器的弱点，尤其是感知器对XOR（异或）这样的简单分类任务都无法解决。Minsky认为，如果将计算层增加到两层，计算量则过大，而且没有有效的学习算法。所以，他认为研究更深层的网络是没有价值的。 &emsp;&emsp;由于Minsky的巨大影响力以及书中呈现的悲观态度，让很多学者和实验室纷纷放弃了神经网络的研究。神经网络的研究陷入了冰河期。这个时期又被称为“AI winter”。接近10年以后，对于两层神经网络的研究才带来神经网络的复苏。 两层神经网络引子&emsp;&emsp;两层神经网络是本文的重点，因为正是在这时候，神经网络开始了大范围的推广与使用。 &emsp;&emsp;Minsky说过单层神经网络无法解决异或问题。但是当增加一个计算层以后，两层神经网络不仅可以解决异或问题，而且具有非常好的非线性分类效果。不过两层神经网络的计算是一个问题，没有一个较好的解法。 &emsp;&emsp;1986年，Rumelhar和Hinton等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。目前，大量的教授神经网络的教材，都是重点介绍两层（带一个隐藏层）神经网络的内容。 &emsp;&emsp;这时候的Hinton还很年轻，30年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。 结构&emsp;&emsp;两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。我们扩展上节的单层神经网络，在右边新加一个层次（只含有一个节点）。 &emsp;&emsp;现在，我们的权值矩阵增加到了两个，我们用上标来区分不同层次之间的变量。 &emsp;&emsp;例如ax(y)代表第y层的第x个节点。z1，z2变成了a1(2)，a2(2)。下图给出了a1(2)，a2(2)的计算公式： 计算最终输出z的方式是利用了中间层的a1(2)，a2(2)和第二个权值矩阵计算得到的，如下图： 假设我们的预测目标是一个向量，那么与前面类似，只需要在“输出层”再增加节点即可。 我们使用向量和矩阵来表示层次中的变量。a(1)，a(2)，z是网络中传输的向量数据。W(1)和W(2)是网络的矩阵参数。 使用矩阵运算来表达整个计算公式的话如下：a(2) = g(W(1) • a(1)), z = g(W(2) • a(2)) 需要说明的是，在两层神经网络中，我们不再使用sgn函数作为函数g，而是使用平滑函数sigmoid作为函数g。我们把函数g也称作激活函数（active function）。这些函数的优点是它们的导数可以使用原函数的值来计算。例如，tanh(x)的导数是1-tanh2(x)，我们只需要计算一次tanh的值，就可以得到它导数的值。 应用与单层神经网络不同。理论证明，两层神经网络可以无限逼近任意连续函数。 这是什么意思呢？也就是说，面对复杂的非线性分类任务，两层（带一个隐藏层）神经网络可以分类的很好。 下面就是一个例子（此两图来自colah的博客），红色的线与蓝色的线代表数据。而红色区域和蓝色区域代表由神经网络划开的区域，两者的分界线就是决策分界。 可以看到，这个两层神经网络的决策分界是非常平滑的曲线，而且分类的很好。有趣的是，前面已经学到过，单层网络只能做线性分类任务。而两层神经网络中的后一层也是线性分类层，应该只能做线性分类任务。为什么两个线性分类任务结合就可以做非线性分类任务？ 我们可以把输出层的决策分界单独拿出来看一下。就是下图 可以看到，输出层的决策分界仍然是直线。关键就是，从输入层到隐藏层时，数据发生了空间变换。也就是说，两层神经网络中，隐藏层对原始的数据进行了一个空间变换，使其可以被线性分类，然后输出层的决策分界划出了一个线性分类分界线，对其进行分类。 这样就导出了两层神经网络可以做非线性分类的关键–隐藏层。联想到我们一开始推导出的矩阵公式，我们知道，矩阵和向量相乘，本质上就是对向量的坐标空间进行一个变换。因此，隐藏层的参数矩阵的作用就是使得数据的原始坐标空间从线性不可分，转换成了线性可分。 两层神经网络通过两层的线性模型模拟了数据内真实的非线性函数。因此，多层的神经网络的本质就是复杂函数拟合。 下面来讨论一下隐藏层的节点数设计。在设计一个神经网络时，输入层的节点数需要与特征的维度匹配，输出层的节点数要与目标的维度匹配。而中间层的节点数，却是由设计者指定的。因此，“自由”把握在设计者的手中。但是，节点数设置的多少，却会影响到整个模型的效果。如何决定这个自由层的节点数呢？目前业界没有完善的理论来指导这个决策。一般是根据经验来设置。较好的方法就是预先设定几个可选值，通过切换这几个值来看整个模型的预测效果，选择效果最好的值作为最终选择。这种方法又叫做Grid Search（网格搜索）。 训练 下面简单介绍一下两层神经网络的训练。 在Rosenblat提出的感知器模型中，模型中的参数可以被训练，但是使用的方法较为简单，并没有使用目前机器学习中通用的方法，这导致其扩展性与适用性非常有限。从两层神经网络开始，神经网络的研究人员开始使用机器学习相关的技术进行神经网络的训练。例如用大量的数据（1000-10000左右），使用算法进行优化等等，从而使得模型训练可以获得性能与数据利用上的双重优势。 机器学习模型训练的目的，就是使得参数尽可能的与真实的模型逼近。具体做法是这样的。首先给所有参数赋上随机值。我们使用这些随机生成的参数值，来预测训练数据中的样本。样本的预测目标为yp，真实目标为y。那么，定义一个值loss，计算公式:loss = (yp - y)2 这个值称之为损失（loss），我们的目标就是使对所有训练数据的损失和尽可能的小。 如果将先前的神经网络预测的矩阵公式带入到yp中（因为有z=yp），那么我们可以把损失写为关于参数（parameter）的函数，这个函数称之为损失函数（loss function）。下面的问题就是求：如何优化参数，能够让损失函数的值最小。 此时这个问题就被转化为一个优化问题。一个常用方法就是高等数学中的求导，但是这里的问题由于参数不止一个，求导后计算导数等于0的运算量很大，所以一般来说解决这个优化问题使用的是最速下降法。最速下降法每次计算参数在当前的梯度，然后让参数向着梯度的反方向前进一段距离，不断重复，直到梯度接近零时截止。一般这个时候，所有的参数恰好达到使损失函数达到一个最低值的状态。 在神经网络模型中，由于结构复杂，每次计算梯度的代价很大。因此还需要使用反向传播算法。反向传播算法是利用了神经网络的结构进行的计算。不一次计算所有参数的梯度，而是从后往前。首先计算输出层的梯度，然后是第二个参数矩阵的梯度，接着是中间层的梯度，再然后是第一个参数矩阵的梯度，最后是输入层的梯度。计算结束以后，所要的两个参数矩阵的梯度就都有了。 反向传播算法可以直观的理解为下图。梯度的计算从后往前，一层层反向传播。前缀E代表着相对导数的意思。 反向传播算法的启示是数学中的链式法则。在此需要说明的是，尽管早期神经网络的研究人员努力从生物学中得到启发，但从BP算法开始，研究者们更多地从数学上寻求问题的最优解。不再盲目模拟人脑网络是神经网络研究走向成熟的标志。正如科学家们可以从鸟类的飞行中得到启发，但没有必要一定要完全模拟鸟类的飞行方式，也能制造可以飞天的飞机。 优化问题只是训练中的一个部分。机器学习问题之所以称为学习问题，而不是优化问题，就是因为它不仅要求数据在训练集上求得一个较小的误差，在测试集上也要表现好。因为模型最终是要部署到没有见过训练数据的真实场景。提升模型在测试集上的预测效果的主题叫做泛化（generalization），相关方法被称作正则化（regularization）。神经网络中常用的泛化技术有权重衰减等。 两层神经网络在多个地方的应用说明了其效用与价值。10年前困扰神经网络界的异或问题被轻松解决。神经网络在这个时候，已经可以发力于语音识别，图像识别，自动驾驶等多个领域。 历史总是惊人的相似，神经网络的学者们再次登上了《纽约时报》的专访。人们认为神经网络可以解决许多问题。就连娱乐界都开始受到了影响，当年的《终结者》电影中的阿诺都赶时髦地说一句：我的CPU是一个神经网络处理器，一个会学习的计算机。 但是神经网络仍然存在若干的问题：尽管使用了BP算法，一次神经网络的训练仍然耗时太久，而且困扰训练优化的一个问题就是局部最优解问题，这使得神经网络的优化较为困难。同时，隐藏层的节点数需要调参，这使得使用不太方便，工程和研究人员对此多有抱怨。 90年代中期，由Vapnik等人发明的SVM（Support Vector Machines，支持向量机）算法诞生，很快就在若干个方面体现出了对比神经网络的优势：无需调参；高效；全局最优解。基于以上种种理由，SVM迅速打败了神经网络算法成为主流。 神经网络的研究再次陷入了冰河期。当时，只要你的论文中包含神经网络相关的字眼，非常容易被会议和期刊拒收，研究界那时对神经网络的不待见可想而知。 多层神经网络引子 在被人摒弃的10年中，有几个学者仍然在坚持研究。这其中的棋手就是加拿大多伦多大学的Geoffery Hinton教授。 2006年，Hinton在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念。与传统的训练方式不同，“深度信念网络”有一个“预训练”（pre-training）的过程，这可以方便的让神经网络中的权值找到一个接近最优解的值，之后再使用“微调”(fine-tuning)技术来对整个网络进行优化训练。这两个技术的运用大幅度减少了训练多层神经网络的时间。他给多层神经网络相关的学习方法赋予了一个新名词–“深度学习”。 很快，深度学习在语音识别领域暂露头角。接着，2012年，深度学习技术又在图像识别领域大展拳脚。Hinton与他的学生在ImageNet竞赛中，用多层的卷积神经网络成功地对包含一千类别的一百万张图片进行了训练，取得了分类错误率15%的好成绩，这个成绩比第二名高了近11个百分点，充分证明了多层神经网络识别效果的优越性。 在这之后，关于深度神经网络的研究与应用不断涌现。 由于篇幅和时间的原因，我们这里不介绍CNN（Conventional Neural Network，卷积神经网络）与RNN（Recurrent Neural Network，递归神经网络）的架构，下面我们只讨论普通的多层神经网络。 结构 我们延续两层神经网络的方式来设计一个多层神经网络。 在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。 依照这样的方式不断添加，我们可以得到更多层的多层神经网络。公式推导的话其实跟两层神经网络类似，使用矩阵运算的话就仅仅是加一个公式而已。 在已知输入a(1)，参数W(1)，W(2)，W(3)的情况下，输出z的推导公式：a(2) = g(W(1) • a(1)), a(3) = g(W(2) • a(2)), z = g(W(3) • a(3)). 多层神经网络中，输出也是按照一层一层的方式来计算。从最外面的层开始，算出所有单元的值以后，再继续计算更深一层。只有当前层所有单元的值都计算完毕以后，才会算下一层。有点像计算向前不断推进的感觉。所以这个过程叫做“正向传播”。 下面讨论一下多层神经网络中的参数。 首先我们看第一张图，可以看出W(1)中有6个参数，W(2)中有4个参数，W(3)中有6个参数，所以整个神经网络中的参数有16个。 假设我们将中间层的节点数做一下调整。第一个中间层改为3个单元，第二个中间层改为4个单元。 经过调整以后，整个网络的参数变成了33个。 虽然层数保持不变，但是第二个神经网络的参数数量却是第一个神经网络的接近两倍之多，从而带来了更好的表示（represention）能力。表示能力是多层神经网络的一个重要性质，下面会做介绍。 在参数一致的情况下，我们也可以获得一个“更深”的网络。 上图的网络中，虽然参数数量仍然是33，但却有4个中间层，是原来层数的接近两倍。这意味着一样的参数数量，可以用更深的层次去表达。 应用 与两层层神经网络不同。多层神经网络中的层数增加了很多。 增加更多的层次有什么好处？更深入的表示特征，以及更强的函数模拟能力。 更深入的表示特征可以这样理解，随着网络的层数增加，每一层对于前一层次的抽象表示更深入。在神经网络中，每一层神经元学习到的是前一层神经元值的更抽象的表示。例如第一个隐藏层学习到的是“边缘”的特征，第二个隐藏层学习到的是由“边缘”组成的“形状”的特征，第三个隐藏层学习到的是由“形状”组成的“图案”的特征，最后的隐藏层学习到的是由“图案”组成的“目标”的特征。通过抽取更抽象的特征来对事物进行区分，从而获得更好的区分与分类能力。 关于逐层特征学习的例子，前面提到的Hubel-Wiesel试验就是一个很好的例子： 更强的函数模拟能力是由于随着层数的增加，整个网络的参数就越多。而神经网络其实本质就是模拟特征与目标之间的真实关系函数的方法，更多的参数意味着其模拟的函数可以更加的复杂，可以有更多的容量（capcity）去拟合真正的关系。 通过研究发现，在参数数量一样的情况下，更深的网络往往具有比浅层的网络更好的识别效率。这点也在ImageNet的多次大赛中得到了证实。从2012年起，每年获得ImageNet冠军的深度神经网络的层数逐年增加，2015年最好的方法GoogleNet是一个多达22层的神经网络。 在最新一届的ImageNet大赛上，目前拿到最好成绩的MSRA(Microsoft Research Asia)团队的方法使用的更是一个深达152层的网络！关于这个方法更多的信息有兴趣的可以查阅ImageNet网站。 训练 在单层神经网络时，我们使用的激活函数是sgn函数。到了两层神经网络时，我们使用的最多的是sigmoid函数。而到了多层神经网络时，通过一系列的研究发现，ReLU函数在训练多层神经网络时，更容易收敛，并且预测性能更好。因此，目前在深度学习中，最流行的非线性函数是ReLU函数。ReLU函数不是传统的非线性函数，而是分段线性函数。其表达式非常简单，就是y=max(x,0)。简而言之，在x大于0，输出就是输入，而在x小于0时，输出就保持为0。这种函数的设计启发来自于生物神经元对于激励的线性响应，以及当低于某个阈值后就不再响应的模拟。 在多层神经网络中，训练的主题仍然是优化和泛化。当使用足够强的计算芯片（例如GPU图形加速卡）时，梯度下降算法以及反向传播算法在多层神经网络中的训练中仍然工作的很好。目前学术界主要的研究既在于开发新的算法，也在于对这两个算法进行不断的优化，例如，增加了一种带动量因子（momentum）的梯度下降算法。 在深度学习中，泛化技术变的比以往更加的重要。这主要是因为神经网络的层数增加了，参数也增加了，表示能力大幅度增强，很容易出现过拟合现象。因此正则化技术就显得十分重要。目前，Dropout技术，以及数据扩容（Data-Augmentation）技术是目前使用的最多的正则化技术。 回顾 我们回顾一下神经网络发展的历程。神经网络的发展历史曲折荡漾，既有被人捧上天的时刻，也有摔落在街头无人问津的时段，中间经历了数次大起大落。 从单层神经网络（感知器）开始，到包含一个隐藏层的两层神经网络，再到多层的深度神经网络，一共有三次兴起过程。详见下图： 上图中的顶点与谷底可以看作神经网络发展的高峰与低谷。图中的横轴是时间，以年为单位。纵轴是一个神经网络影响力的示意表示。如果把1949年Hebb模型提出到1958年的感知机诞生这个10年视为落下（没有兴起）的话，那么神经网络算是经历了“三起三落”这样一个过程，跟“小平”同志类似。俗话说，天将降大任于斯人也，必先苦其心志，劳其筋骨。经历过如此多波折的神经网络能够在现阶段取得成功也可以被看做是磨砺的积累吧。 历史最大的好处是可以给现在做参考。科学的研究呈现螺旋形上升的过程，不可能一帆风顺。同时，这也给现在过分热衷深度学习与人工智能的人敲响警钟，因为这不是第一次人们因为神经网络而疯狂了。1958年到1969年，以及1985年到1995，这两个十年间人们对于神经网络以及人工智能的期待并不现在低，可结果如何大家也能看的很清楚。 因此，冷静才是对待目前深度学习热潮的最好办法。如果因为深度学习火热，或者可以有“钱景”就一窝蜂的涌入，那么最终的受害人只能是自己。神经网络界已经两次有被人们捧上天了的境况，相信也对于捧得越高，摔得越惨这句话深有体会。因此，神经网络界的学者也必须给这股热潮浇上一盆水，不要让媒体以及投资家们过分的高看这门技术。很有可能，三十年河东，三十年河西，在几年后，神经网络就再次陷入谷底。根据上图的历史曲线图，这是很有可能的。 下面说一下神经网络为什么能这么火热？简而言之，就是其学习效果的强大。随着神经网络的发展，其表示性能越来越强。 从单层神经网络，到两层神经网络，再到多层神经网络，下图说明了，随着网络层数的增加，以及激活函数的调整，神经网络所能拟合的决策分界平面的能力。 可以看出，随着层数增加，其非线性分界拟合能力不断增强。图中的分界线并不代表真实训练出的效果，更多的是示意效果。 神经网络的研究与应用之所以能够不断地火热发展下去，与其强大的函数拟合能力是分不开关系的。 当然，光有强大的内在能力，并不一定能成功。一个成功的技术与方法，不仅需要内因的作用，还需要时势与环境的配合。神经网络的发展背后的外在原因可以被总结为：更强的计算性能，更多的数据，以及更好的训练方法。只有满足这些条件时，神经网络的函数拟合能力才能得已体现，见下图： 之所以在单层神经网络年代，Rosenblat无法制作一个双层分类器，就在于当时的计算性能不足，Minsky也以此来打压神经网络。但是Minsky没有料到，仅仅10年以后，计算机CPU的快速发展已经使得我们可以做两层神经网络的训练，并且还有快速的学习算法BP。 但是在两层神经网络快速流行的年代。更高层的神经网络由于计算性能的问题，以及一些计算方法的问题，其优势无法得到体现。直到2012年，研究人员发现，用于高性能计算的图形加速卡（GPU）可以极佳地匹配神经网络训练所需要的要求：高并行性，高存储，没有太多的控制需求，配合预训练等算法，神经网络才得以大放光彩。 互联网时代，大量的数据被收集整理，更好的训练方法不断被发现。所有这一切都满足了多层神经网络发挥能力的条件。 “时势造英雄”，正如Hinton在2006年的论文里说道的 …provided that computers were fast enough, data sets were big enough, and the initial weights were close enough to a good solution. All three conditions are now satisfied. 外在条件的满足也是神经网络从神经元得以发展到目前的深度神经网络的重要因素。 建立神经网络&emsp;&emsp;介绍完神经网络的概况，我们来尝试建立一个具有一个输入层，一个隐藏层，一个输出层的神经网络。输入层的节点数由数据的维度决定，这里是2；输出层的节点数由类别的数量决定，这里也是2。因为我们只有两类输出，实际中我们会避免只使用一个输出结点预测0和1，而是使用两个输出结点以使网络以后能很容易地扩充到更多的类别。在这里，网络的输入是坐标，输出的是概率，一个是0的概率，一个是1的概率。 &emsp;&emsp;我们可以设定隐藏层的结点数。放入隐藏层的结点越多，我们能训练的函数也就越复杂，但同时，训练的代价与维度（隐藏层结点数）是成正相关的。预测和学习网络的参数越多就需要更多的计算时间，参数越多也就意味着我们可能会过度拟合数据（这点在之后给大家讲）。 &emsp;&emsp;在神经网络中，每个处理单元事实上就是一个逻辑回归模型，逻辑回归模型接收上层的输入，把模型的预测结果作为输出传输到下一个层次。通过这样的过程，神经网络可以完成非常复杂的非线性分类。 &emsp;&emsp;我们还需要为隐藏层挑选一个激活函数。激活函数将该层的输入转换为输出。一个非线性激活函数允许我们拟合非线性假设。常用的激活函数有sigmoid函数或者是ReLUs)。这里我们选择使用在很多场景下都能表现很好的tanh函数。 &emsp;&emsp;因为我们想要得到神经网络输出概率，所以输出层的激活函数就要是softmax。这是一种将原始分数转换为概率的方法。如果你很熟悉logistic回归，可以把softmax看作是它在多类别上的一般化。 &emsp;&emsp;输出层为softmax时多会选择交叉熵损失（cross-entropy loss）最为损失函数。假如我们有N个训练例子和C个分类，那么预测值（hat{y}）相对真实标签值的损失就由下列公式给出： &emsp;&emsp;这个公式看起来很复杂，但实际上它所做的事情不过是把所有训练例子求和，然后加上预测值错误的损失。所以，预测值距离真实标签值越远，损失值就越大。至于为什么这里不采用欧式距离来计算，大家可以参考信息论中的信息熵的知识。 &emsp;&emsp;要记住，我们的目标是找到能最小化损失函数的参数值。我们可以使用梯度下降方法找到最小值。我会实现最速下降法的一种最普通的版本。诸如SGD（随机梯度下降）或minibatch梯度下降通常在实践中有更好的表现。所以，如果你是认真的，这些可能才是你的选择，最好还能逐步衰减学习率。 &emsp;&emsp;我们住了使用前文中提到的后向传播算法。在这里我不会深入讲解后向传播如何工作，但是在网络上流传有很多很优秀的讲解（参见colah的博文-Calculus on Computational Graphs: Backpropagation）。 现在我们要准备开始实现网络了。我们从定义梯度下降一些有用的变量和参数开始： 1234567num_examples = len(X) # training set sizenn_input_dim = 2 # input layer dimensionalitynn_output_dim = 2 # output layer dimensionality# Gradient descent parameters (I picked these by hand)epsilon = 0.01 # learning rate for gradient descentreg_lambda = 0.01 # regularization strength 接着要实现我们上面定义的损失函数。以此来衡量我们的模型工作得如何： 123456789101112131415# Helper function to evaluate the total loss on the datasetdef calculate_loss(model): W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation to calculate our predictions z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Calculating the loss corect_logprobs = -np.log(probs[range(num_examples), y]) data_loss = np.sum(corect_logprobs) # Add regulatization term to loss (optional) data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2))) return 1./num_examples * data_loss 还要实现一个辅助函数来计算网络的输出。它的工作就是传递前面定义的前向传播并返回概率最高的类别。 12345678910# Helper function to predict an output (0 or 1)def predict(model, x): W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation z1 = x.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) return np.argmax(probs, axis=1) 最后是训练神经网络的函数。它使用上文中发现的后向传播导数实现批量梯度下降。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# This function learns parameters for the neural network and returns the model.# - nn_hdim: Number of nodes in the hidden layer# - num_passes: Number of passes through the training data for gradient descent# - print_loss: If True, print the loss every 1000 iterationsdef build_model(nn_hdim, num_passes=20000, print_loss=False): # Initialize the parameters to random values. We need to learn these. np.random.seed(0) W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim) b1 = np.zeros((1, nn_hdim)) W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim) b2 = np.zeros((1, nn_output_dim)) # This is what we return at the end model = &#123; &#125; # Gradient descent. For each batch... for i in xrange(0, num_passes): # Forward propagation z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Backpropagation delta3 = probs delta3[range(num_examples), y] -= 1 dW2 = (a1.T).dot(delta3) db2 = np.sum(delta3, axis=0, keepdims=True) delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) dW1 = np.dot(X.T, delta2) db1 = np.sum(delta2, axis=0) # Add regularization terms (b1 and b2 don't have regularization terms) dW2 += reg_lambda * W2 dW1 += reg_lambda * W1 # Gradient descent parameter update W1 += -epsilon * dW1 b1 += -epsilon * db1 W2 += -epsilon * dW2 b2 += -epsilon * db2 # Assign new parameters to the model model = &#123; 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2&#125; # Optionally print the loss. # This is expensive because it uses the whole dataset, so we don't want to do it too often. if print_loss and i % 1000 == 0: print "Loss after iteration %i: %f" %(i, calculate_loss(model)) return model 下面贴出完整的代码，一起来看看假如我们训练了一个隐藏层规模为3的神经网络会发生什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146import matplotlibimport numpy as npfrom sklearn import datasets, linear_modelimport matplotlib.pyplot as plt%matplotlib inlineclass Config: nn_input_dim = 2 # input layer dimensionality nn_output_dim = 2 # output layer dimensionality # Gradient descent parameters (I picked these by hand) epsilon = 0.01 # learning rate for gradient descent reg_lambda = 0.01 # regularization strengthdef generate_data(): np.random.seed(0) X, y = datasets.make_moons(300, noise=0.20) return X, ydef visualize(X, y, model): plot_decision_boundary(lambda x:predict(model,x), X, y) fig = matplotlib.pyplot.gcf() fig.set_size_inches(18.5, 10.5)def plot_decision_boundary(pred_func, X, y): # Set min and max values and give it some padding x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 h = 0.01 # Generate a grid of points with distance h between them xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) # Predict the function value for the whole gid Z = pred_func(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) # Plot the contour and training examples plt.xkcd() plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral) plt.scatter(X[:, 0], X[:, 1], s=60, c=y, cmap=plt.cm.Spectral) plt.title("Decision Boundary for hidden layer size 3") # plt.show()# Helper function to evaluate the total loss on the datasetdef calculate_loss(model, X, y): num_examples = len(X) # training set size W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation to calculate our predictions z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Calculating the loss corect_logprobs = -np.log(probs[range(num_examples), y]) data_loss = np.sum(corect_logprobs) # Add regulatization term to loss (optional) data_loss += Config.reg_lambda / 2 * (np.sum(np.square(W1)) + np.sum(np.square(W2))) return 1. / num_examples * data_lossdef predict(model, x): W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation z1 = x.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) return np.argmax(probs, axis=1)# This function learns parameters for the neural network and returns the model.# - nn_hdim: Number of nodes in the hidden layer# - num_passes: Number of passes through the training data for gradient descent# - print_loss: If True, print the loss every 1000 iterationsdef build_model(X, y, nn_hdim, num_passes=20000, print_loss=False): # Initialize the parameters to random values. We need to learn these. num_examples = len(X) np.random.seed(0) W1 = np.random.randn(Config.nn_input_dim, nn_hdim) / np.sqrt(Config.nn_input_dim) b1 = np.zeros((1, nn_hdim)) W2 = np.random.randn(nn_hdim, Config.nn_output_dim) / np.sqrt(nn_hdim) b2 = np.zeros((1, Config.nn_output_dim)) # This is what we return at the end model = &#123; &#125; # Gradient descent. For each batch... for i in range(0, num_passes): # Forward propagation z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Backpropagation delta3 = probs delta3[range(num_examples), y] -= 1 dW2 = (a1.T).dot(delta3) db2 = np.sum(delta3, axis=0, keepdims=True) delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) dW1 = np.dot(X.T, delta2) db1 = np.sum(delta2, axis=0) # Add regularization terms (b1 and b2 don't have regularization terms) dW2 += Config.reg_lambda * W2 dW1 += Config.reg_lambda * W1 # Gradient descent parameter update W1 += -Config.epsilon * dW1 b1 += -Config.epsilon * db1 W2 += -Config.epsilon * dW2 b2 += -Config.epsilon * db2 # Assign new parameters to the model model = &#123;'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2&#125; # Optionally print the loss. # This is expensive because it uses the whole dataset, so we don't want to do it too often. if print_loss and i % 1000 == 0: print("Loss after iteration %i: %f" % (i, calculate_loss(model, X, y))) return modeldef classify(X, y): # clf = linear_model.LogisticRegressionCV() # clf.fit(X, y) # return clf passdef main(): X, y = generate_data() model = build_model(X, y, 3, print_loss=True) visualize(X, y, model)if __name__ == "__main__": main() Loss after iteration 0: 0.381135 Loss after iteration 1000: 0.065193 Loss after iteration 2000: 0.062375 Loss after iteration 3000: 0.062123 Loss after iteration 4000: 0.062039 Loss after iteration 5000: 0.062626 Loss after iteration 6000: 0.063454 Loss after iteration 7000: 0.063059 Loss after iteration 8000: 0.062421 Loss after iteration 9000: 0.067547 Loss after iteration 10000: 0.062120 Loss after iteration 11000: 0.061861 Loss after iteration 12000: 0.064949 Loss after iteration 13000: 0.061784 Loss after iteration 14000: 0.064258 Loss after iteration 15000: 0.062042 Loss after iteration 16000: 0.062150 Loss after iteration 17000: 0.064294 Loss after iteration 18000: 0.062985 Loss after iteration 19000: 0.063395 这看起来结果相当不错。我们的神经网络能够找到成功区分类别的决策边界。 在上述例子中，我们选择了隐藏层规模为3。现在来看看改变隐藏层规模会对结果造成怎样的影响。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139import numpy as npfrom sklearn import datasets, linear_modelimport matplotlib.pyplot as pltimport time%matplotlib inlineclass Config: nn_input_dim = 2 # input layer dimensionality nn_output_dim = 2 # output layer dimensionality # Gradient descent parameters (I picked these by hand) epsilon = 0.01 # learning rate for gradient descent reg_lambda = 0.01 # regularization strengthdef generate_data(): np.random.seed(0) X, y = datasets.make_moons(300, noise=0.20) return X, ydef visualize(X, y, model): plot_decision_boundary(lambda x:predict(model,x), X, y)def plot_decision_boundary(pred_func, X, y): # Set min and max values and give it some padding x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 h = 0.01 # Generate a grid of points with distance h between them xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) # Predict the function value for the whole gid Z = pred_func(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) # Plot the contour and training examples plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral) plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)# Helper function to evaluate the total loss on the datasetdef calculate_loss(model, X, y): num_examples = len(X) # training set size W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation to calculate our predictions z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Calculating the loss corect_logprobs = -np.log(probs[range(num_examples), y]) data_loss = np.sum(corect_logprobs) # Add regulatization term to loss (optional) data_loss += Config.reg_lambda / 2 * (np.sum(np.square(W1)) + np.sum(np.square(W2))) return 1. / num_examples * data_lossdef predict(model, x): W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2'] # Forward propagation z1 = x.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) return np.argmax(probs, axis=1)# This function learns parameters for the neural network and returns the model.# - nn_hdim: Number of nodes in the hidden layer# - num_passes: Number of passes through the training data for gradient descent# - print_loss: If True, print the loss every 1000 iterationsdef build_model(X, y, nn_hdim, num_passes=20000, print_loss=False): # Initialize the parameters to random values. We need to learn these. num_examples = len(X) np.random.seed(0) W1 = np.random.randn(Config.nn_input_dim, nn_hdim) / np.sqrt(Config.nn_input_dim) b1 = np.zeros((1, nn_hdim)) W2 = np.random.randn(nn_hdim, Config.nn_output_dim) / np.sqrt(nn_hdim) b2 = np.zeros((1, Config.nn_output_dim)) # This is what we return at the end model = &#123; &#125; # Gradient descent. For each batch... for i in range(0, num_passes): # Forward propagation z1 = X.dot(W1) + b1 a1 = np.tanh(z1) z2 = a1.dot(W2) + b2 exp_scores = np.exp(z2) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # Backpropagation delta3 = probs delta3[range(num_examples), y] -= 1 dW2 = (a1.T).dot(delta3) db2 = np.sum(delta3, axis=0, keepdims=True) delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2)) dW1 = np.dot(X.T, delta2) db1 = np.sum(delta2, axis=0) # Add regularization terms (b1 and b2 don't have regularization terms) dW2 += Config.reg_lambda * W2 dW1 += Config.reg_lambda * W1 # Gradient descent parameter update W1 += -Config.epsilon * dW1 b1 += -Config.epsilon * db1 W2 += -Config.epsilon * dW2 b2 += -Config.epsilon * db2 # Assign new parameters to the model model = &#123;'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2&#125; # Optionally print the loss. # This is expensive because it uses the whole dataset, so we don't want to do it too often. if print_loss and i % 1000 == 0: print("Loss after iteration %i: %f" % (i, calculate_loss(model, X, y))) return modeldef main(): X, y = generate_data() plt.figure(figsize=(16, 32)) hidden_layer_dimensions = [1, 2, 3, 4, 5, 20, 50, 100] for i, nn_hdim in enumerate(hidden_layer_dimensions): start = time.clock() plt.subplot(5, 2, i+1) model = build_model(X, y, nn_hdim) plot_decision_boundary(lambda x:predict(model,x), X, y) end = time.clock() plt.title("Hidden Layer size %d, consuming time: %d s" % (nn_hdim, end-start))# print "Hidden Layer size %d, consuming time: %d s" % (nn_hdim, end-start) plt.show()if __name__ == "__main__": main() &emsp;&emsp;可以看到，低维隐藏层能够很好地捕捉到数据的总体趋势。更高的维度则更倾向于过拟合，由于时间限制，这里我没办法详细介绍过拟合，大家请参见一篇文章,带你明白什么是过拟合,欠拟合以及交叉验证。它们更像是在“记忆”数据而不是拟合数据的大体形状。假如我们打算在独立测试集上评测该模型（你也应当这样做），隐藏层规模较小的模型会因为能更好的泛化而表现更好。虽然我们可以使用更强的泛化来抵消过拟合，但是为隐藏层选择一个合适的规模无疑是更加“经济”的方案。 参考资料 Andrew Ng Courera Machine Learning Neural Networks 神经网络简史 中科院 史忠植 神经网络 讲义 深度学习 胡晓林]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[青春为伴，玩转青海]]></title>
      <url>%2F2016%2F07%2F03%2Fqh%2F</url>
      <content type="text"><![CDATA[很长时间没有写这么多文字了，文笔很差，大家谅解。这篇游记不仅有我们一行四人游玩的记录，还有一些背景文化的介绍，若实在看不下去，就刷刷图片吧，若图片也觉得不行，那就在评论区吐槽我吧。 前言&emsp;&emsp;在一行另外几个人写游记的时候，我吐槽他们是在写流水账，浪费了党和国家十多年来的教育。在我提笔，准确来说是敲键盘，写这篇游记的时候，心中不免有些忐忑。其实我作文一直都不怎么好，吐槽队友只是纯属搞笑。 &emsp;&emsp;小时候的经历在很大程度上决定了我现在出游的方式（不过这篇游记不是讲我过去的经历的，所以就不提了），热闹繁华的大都市是我所不喜的，反而更偏爱人烟稀少的地方。背上行囊，装着帐篷、睡袋、水壶以及其他的必需品就可以开始旅行。多数时候是和志同道合的朋友一起，当然也少不了自己独自一人行走的时候。没错，我这类人一般被称为驴友。&emsp;&emsp;大三已进入尾声，不爽的就是还拖着一个小学期，无聊的课程内容和磨人的时间安排让我实在提不起兴趣。在快要考试周的时候，饼干问我小学期有没有出游的打算，登时我便来劲了。“去青海吧，”他对我说，“去青海湖玩玩。”不错的目的地，我有些动心。青海我以前去过一次，但没有去青海湖，而是去登可可赛门极峰了，直接就从北京到了格尔木。正对小学期十分厌烦的我爽快地接受了他的建议。 &emsp;&emsp;最后决定自驾，住主要是住青旅和帐篷。两人租一辆车着实有些“奢华”，于是又在朋友圈发动态约了另外三个同伴，后来一个同伴零时有事没能一起，最后饼干、小鱼、熊猫和我一行四人准备六月二十七号出发去青海。 行程总览 行程时间 主要地点 里程 开销 D1 T175次列车 － 火车824 D2 T175次列车、塔尔寺、西宁市中心 － 塔尔寺门票160（学生票），青旅184 D3 青海湖、茶卡盐湖（未游玩）、黑马河 426.7km 过路费45，青海湖门票（给藏民）80，营地70 D4 黑马河日出、茶卡盐湖、青海湖 284.9km 过路费30，茶卡盐湖门票100（学生票），营地40 D5 卓尔山、门源 481.6km 卓尔山门票120，过路费20，青旅171 D6 西宁、T176次列车 20km 火车1442 D7 抵达北京 － － 表格中仅记录路途中团体主要开销 项目 开销 项目 开销 租车 ¥831 火车 ¥2266 汽油 ¥450 门票 ¥460 住宿 ¥465 吃、用等杂项 ¥1689.9 过路费 ¥95 - - 总计 ¥6256.9 D1：硬座火车之旅&emsp;&emsp;一个是以我喜爱穷游的性格，另一个是买票的时间有些晚，最后给大家买了硬座票。不得不说定的集合时间简直将时间点卡到了极致，在发车的前两三分钟，我们才勉强冲上火车。四个人背着数十升的登山包在地铁站和火车站狂奔的景象真是令人迷醉。 &emsp;&emsp;我们乘坐的是T175次列车，从北京到西宁需要二十余小时的时间，这对于不怎么习惯长时间坐硬座的人来说确实是一种折磨。小鱼几乎是一宿没有闭眼。至于我们的饼干，也变身成为了忍者神龟。我们的神龟在车上相当的能睡，基本上坐着一会就能睡着，这让队伍中两个女生羡慕不已。 D2：莲花山上的净土终抵西宁&emsp;&emsp;一夜辗转难眠之后，终于到达了此行的“起点”——西宁市。一位热情的小哥为我们拍下了一张合影，从左到右依次为博主本人，小鱼，熊猫和饼干。 &emsp;&emsp;在这个时节，北京已经被太阳炙烤得酷热难当，然而地处青藏高原的西宁却让人感到丝丝凉爽。在西宁，迎面而来的风，也是轻柔的，带走心中那淡淡的烦躁，也许是由于青藏高原是最接近“天”的大地吧。 &emsp;&emsp;出了火车站继续往前走，过了河，在经过一个红绿灯，向前走一百来米，在那坐上了1路公交车（西宁大多数公交票价均为一元），到了大十字站下车，顺着百度地图的指引来到了今晚留宿的地方——青海行青年旅社。旅社地处西宁市中心，离中心广场、王府井、莫家街等地就几分钟脚程，购物和吃饭十分方便。走上旅社的楼梯，略带藏族气息的装饰让我倍感亲切，仿佛又回到了林芝那个令人沉醉的地域。在我拍照位置的左手边设有桌椅，可供驴友们晚上互相交流。楼下有户外用品店和烧烤用品店，想要在青海湖边自己煮火锅、烤烧烤的驴友不必担心气罐没法过火车站安检（Ps. 博主一行人在旅舍前台留下了三个多余的气罐，有需要的驴友可以找前台）。 &emsp;&emsp;这家青年旅社的条件还不错，除了洗澡用的电热水器用的时间过长会没热水。我们只有四个人，老板却给我们开了一个五人间，只收了四个床位的钱，还带独卫。没有专门拍房间内部，只好给一张饼干哥在床上的照片让大家看看房屋的条件： &emsp;&emsp;旅途的劳顿并没有打消大家探索西宁的积极性。放下行囊略作休憩后，一行四人就开始了在西宁的第一大任务——吃！接受了同学蒋红才（他是西宁本地人）的建议，我们就在附近随便找了一家餐馆（他建议我们去大十字周围，说路边随便找一家餐馆味道都很不错，也不贵。由于我们住的旅社就在大十字附近，所以就在附近找了）。可惜就是当时太着急吃东西，没有记下餐馆的名字，也就没办法安利给大家了。但那个地方离旅舍很近，就几百米。 &emsp;&emsp;要了一份酿皮，四碗手工酸奶，两碗炒面，一碗青稞面片，一碗牛肉面，总共九十一块钱。第一次感觉自己的食量是那么小，在我们的肚子连一丁点水都装不下去之后，居然还没将这些食物吃完，一向点多少吃多少的博主深受打击。强烈建议大家试一试手工酸奶，柔和的触感，入口即化，带着丝丝的酸甜，好似令你全身上下所有毛孔都张开了，身体中所有浊气顺势而出，二十多小时的硬座带来的疲劳顿时消失殆尽。 雪域圣迹，宗喀巴大师诞生地——塔尔寺&emsp;&emsp;饭店附近有个公交车站，在那坐3路车，在管理站下车，这里有直达塔尔寺的公交车，票价3元，车程40分钟到1个小时左右。 &emsp;&emsp;这是一方净土，这是一块圣地。朝拜、旅游观光的队伍涌向这里，人们来自四面八方，来自千里之外。信徒们几乎是用自己的身体丈量大地，虔诚地奔向他们心中的神灵；旅行家瞄准的则是世界文化遗产的宝库，是青藏高原民族信仰和地域风光交织而成的神奇画卷。先让我用仅有的见识介绍一下塔尔寺。 汉藏艺术风格相结合的建筑特色 &emsp;&emsp;塔尔寺坐落于青海省湟中县鲁沙尔镇西南隅的莲花山坳中，距省会西宁市26公里，是我国藏传佛教格鲁派（俗称黄教)创始人宗喀巴大师的诞生地和藏族聚居区格鲁派六大寺院之一。寺庙的建筑涵盖了汉式传统宫殿与藏族平顶建筑的风格，独具匠心地把汉式三檐歇山式与藏族檐下巧砌边玛墙、中镶金刚时轮梵文咒和铜镜、底层镶砖的形式融为一体，和谐完美地组成汉藏艺术风格相结合的建筑群。塔尔寺不仅是我国的藏传佛教圣地，而且是造就大批藏族知识分子的高级学府之一，寺内设有显宗、密宗、天文、医学四大学院。 建佛塔如见宗喀巴，未建寺先有塔 &emsp;&emsp;宗喀巴殿内，一尊头戴黄色僧帽、身着鹅黄色袈裟、手执佛印、面容慈祥而又庄重的镀金佛像就是宗喀巴大师像。宗喀巴是藏传佛教学说的集大成者，班禅、达赖两大活佛正是宗喀巴大师的弟子。因先有塔后有寺，故而称之为“塔尔寺”。 艺术三绝：酥油花、堆绣和壁画 &emsp;&emsp;塔尔寺以酥油花、壁画和堆绣闻名于世，它们被称为塔尔寺的“艺术三绝”。每逢农历正月十五，酥油花如期展出。用酥油作原料的佛祖塑像神采奕奕，佛像周围是以佛教故事为主要内容的塑像群，人物栩栩如生，花朵枝叶五彩斑斓，是举世无双的造型艺术。塔尔寺堆绣是将刺绣与浮雕手法完美结合的工艺美术品，层层用彩绸堆制而成的花朵令人耳目一新。塔尔寺壁画遍布寺内高大的墙壁上，重彩工笔，描绘精致，具有浓郁的雪域高原风味。 &emsp;&emsp;塔尔寺最具魅力的地方是民族风情浓郁的宗教活动。塔尔寺的四大法会又称四大祈愿法会，分别于农历正月、四月、六月、九月举行。法会期间，难得的酥油花展、跳神舞隆重举行，塔尔寺人山人海。大家盼望已久的晒佛仪式十分感人，梵乐悠扬，阳光遍洒，巨大的佛像从山顶向山下徐徐展开，人们顿觉祥云盖顶，佛光四照。 &emsp;&emsp;拜谒塔尔寺的人们更为迫切的心愿是去拜见塔尔寺活佛。鼎盛时期，塔尔寺共有83位活佛。活佛转世的过程庄重又神秘：打卦问卜，降神，依照遗言，预示，辨认遗物，金瓶掣签，经历这样的过程，转世灵童就出现了。活佛被认定后，要举行隆重的坐床典礼。塔尔寺的活佛常常为众生摩顶，接受摩顶的人们就是沐浴到了慈祥而温暖的佛光。虔诚的人们还带去自己心爱的物品祈求活佛开光。开光后，这物品便有了非同寻常的意义，成了吉祥物。可以说，寻找塔尔寺，就是寻找吉祥和幸福。 &emsp;&emsp;在宗喀巴诞生的地方，四周峰峦重叠。塔尔寺安居于莲花山中心，千瓣莲花又成为瑞祥的征兆。湟水流过这片土地，数千年的文明留下无数意味探长的背影。 &emsp;&emsp;塔尔寺是雪域高原上当之无愧的圣地，是吉祥的象征、幸福的源泉、心灵的寄托、虔诚的向往。 &emsp;&emsp;虽然我个人是一个无神论者，但是在西藏生活了几年，耳濡目染之下，对藏传佛教也有些许的了解。在一个庙宇中，碰巧遇见导游在向游客介绍磕长头。虽然时隔多年，可又见到这种“五体投地”的跪拜方式，说心中没有波动是不可能的。队伍中的两个女生听完介绍后也偷偷抹了抹眼角。 &emsp;&emsp;“磕长头”为等身长头，五体投地匍匐，双手前直伸。每伏身一次，以手划地为号，起身后前行到记号处再匍匐，如此周而复始。遇河流，须涉水、渡船，则先于岸边磕足河宽，再行过河。晚间休息后，需从昨日磕止之处启程。虔诚之至，千里不遥，坚石为穿，令人感叹。 &emsp;&emsp;在各地通往拉萨的大道上，人们不时地见到信徒们从遥远的故乡开始，手戴护具，膝着护膝，前身挂一毛皮衣物，尘灰覆面，沿着道路，不惧千难万苦，三步一磕，直至拉萨朝佛。磕长头的信徒绝不会用偷懒的办法来减轻劳累，遇有交错车辆或因故暂停磕头，则划线或积石为志，就这样不折不扣，矢志不渝，靠坚强的信念，步步趋向圣城拉萨。 &emsp;&emsp;即使我不信佛，但也是异常倾佩他们对于佛的虔诚。写到这里，我又想起了我那已经过世的奶奶，她是一个虔诚的佛教徒。我想，如果她能够站在这寺庙之中，诵经、念佛、朝拜一定会很开心吧。只可惜这件事只能存在于想象之中了。 &emsp;&emsp;藏传佛教中，转经轮是不可或缺的元素，下面给大家说说转经轮的起源。观音菩萨曾对龙树授记：“龙宫中的龙菩萨，拥有一座转经轮；任何众生只要见到、听到、想到、碰触到，即能从下三道的痛苦中解脱；如果您能获得此座转经轮，就可利益无量众生。”于是龙树菩萨前往龙宫，告诉龙菩萨有关观音菩萨的授记，并请求给予此座珍贵的转经轮。 &emsp;&emsp;当时龙菩萨说：“此座珍贵的转经轮，是由过去佛燃灯佛时赐予龙族的，具有大威力，能令六道众生从极大痛苦中解脱，同时也可保护龙族。”在给予龙树菩萨此座经轮的同时，并告知可利用四大，转动此座珍贵的转经轮以利益众生。后来，龙树菩萨将此转经轮交给狮面空行母，传入西藏，普遍于藏区各大小寺院及男女老幼。 &emsp;&emsp;由藏密成就者流传下来的转经轮很多，密宗始祖莲花生大士曾传下各种不同转经轮，阿底峡尊者、马尔巴等大师曾传下一些转经轮，并曾提到转经轮功德殊胜、不分根器，凡夫以此持诵咒语或佛号时，纵有任何妄念、妄想、瞋念或忘记回向等过失，亦不会损及转动经轮的各种功德利益。 &emsp;&emsp;其实，我本不是一个无神论者。小时候的我，对于佛抱有无边的崇敬和尊重。小时候生活在西藏，那时正是好奇心强盛的时期，我对于藏传佛教的理解，几乎就是在那个时候建立起来的。在后来的生活中，对于佛，我逐渐失去了信心，慢慢的，我变得没有了信仰。 &emsp;&emsp;虽然我不信佛，但其实我也不摒弃佛家所有的东西，不然我也不会来到这座在风雪中走过数百年的寺庙。我没有藏传佛教信徒那种磕十万长头以祈众生安乐的毅力和胸怀，也没有佛家大师普渡众生的宏愿。而这些正是我所倾佩的，所以我来到这里，听其言，观其行，悟其神。 &emsp;&emsp;走走停停间，时间悄然逝去。每天下午五点的时候塔尔寺便会闭寺诵经，也就是宣告着游人请离开寺庙。 大家的合影： &emsp;&emsp;雪域圣迹，塔尔寺之行就先给大家介绍到这儿，接下来是该回西宁吃晚饭的时间了！ D3:游山玩水看风光贡毛拉 &emsp;&emsp;拉鸡山属日月山支脉，藏语称“贡毛拉”，意为尕拉鸡（石鸡）栖息的地方.虽然六月已进入尾声，但山风还带着些许的凉意，扑在身上，说不出的爽快。但是太阳并不像风那样友好，喷洒着大量的紫外线，若将皮肤裸露在外，一会儿便有些痛感。 大家和座驾🚗的合影 女生总是爱花的鱼哥这时候又摆出了她的怪动作远离都市的喧嚣，远离夏日的灼热，每一个笑容都是那样的甜美一心想要模仿Michael Jackson的饼干“好吃不过饺子，舒服不过躺着”（用天津口音读）这是帽子要被吹走了吗坐姿自由女神像 大话经幡&emsp;&emsp;缓缓驱车向前，不多时，在道路右侧遇到了我们这几天见到的完美的经幡。将车停在路边，一起向着经幡经幡冲去，不过由于在高原上，两个女孩子体能有些跟不上。 &emsp;&emsp;这些方形、角形、条形的小旗被有秩序地固定在门首、绳索、族幢、树枝上，在大地与苍穹之间飘荡摇曳，构成了一种连地接天的境界。 成串成串拉挂在亭子和松树间的彩旗，印满密密麻麻的藏文咒语、经文、佛像、吉祥物图形。 &emsp;&emsp;藏区各山河路口寺庙民舍等处都可见到印有经文图案成串系于绳索之上的小旗，这一面面小旗在藏语中称为“隆达”，也有人称之为“祭马”、“禄马”、“经幡”、“祈愿幡”，不过，在藏区，人们更习惯称它为“风马旗”，因为“隆”在藏语中是风的意思，“达”是马的意思。 &emsp;&emsp;一般认为风马源于一种原始祭祀文化，主要由对动物魂灵的崇拜而来。最初的风马是直接将羊毛系挂于树枝草丛，如今在大大小小的玛尼堆上仍可看到牛羊头颅等物。藏族原始宗教认为，山神是地方保护神，它无时无刻不在注视着本地区众生的安全，常骑马巡视辖区，保护一方水土和人畜平安。 &emsp;&emsp;藏族认为，“风马”在深层意义上指人的气数和运道，或者特指五行；在灵气聚集之处（神山圣湖等），挂置印有敬畏神灵和祈求护佑等愿望的风马，让风吹送，有利于愿望向上苍神灵的传达和实现。为报答山神和上苍神灵，每到祭日，人们便虔诚地举行煨桑仪式，献上“隆达”。所以制作插挂“隆达”成为不可或缺的仪轨。 &emsp;&emsp;风马旗的祭祀活动，与其图像象征内涵有关。经幡的中心是一匹骏马，骏马形象是神速的象征。祈愿受五种自然物制约的世间一切事物，由对立转向和睦，由坏转向好，由恶转向善，由凶兆转向吉兆，由厄运转向幸运。不仅能够转变，而且转变得迅速。经幡四角画的四兽图像，老虎栖息在森林中，老虎的形象象征着木或风；狮子居于山上，狮子的形象象征着土；鹏鸟飞翔在天空，双角喷发出火焰，这种形象象征着火；龙生活在大海中，鱼龙的形象象征着水。风无处不在，风即天。 &emsp;&emsp;在这里没有把森林、高山、大地、天空、河水、大海作为六种自然物直接画上去，而把在这些环境中生活的动物形象作象征，可见它不是仅仅表现六种自然物，而是把它们作为主要内容。 &emsp;&emsp;而马背上画的那个象征财运的“喷焰末巴”，就是促成实现人们心愿的如意吉祥。除开分别不同的五色象征之外，一般还有一面主幡，形制要大于五种不同单色的经幡。主幡与边镶布条颜色搭配，是根据藏族历算关于母子生克学说中相生原理来决定的，如主幡的颜色是绿色，边镶布条的颜色应该是蓝色，主木水相生。故而马经幡象征着生命的本源，具有深奥的意义，整个经幡完全是融情感与理性为一体的产物，完全是表现人们美好精神愿望的载体。 &emsp;&emsp;但在最初的实际运用中，风马旗并不是寄托藏人祭祀神灵、祈祥祛难的心愿的，而是军队的标志。根据才情横溢的根敦群佩著作《白史》称：大部分臣民皆为游牧，每户门上都立一根旗矛，这是藏族独有的习俗。此亦最早是军户的标识，后演变成为一种宗教习俗行为。哪怕是一户也要在门上插经幡，一直保持到现在。 措温布 &emsp;&emsp;青海湖，藏语名为“措温布”（意为“青色的海”）。古称西海、鲜水、鲜海、卑禾羌海。位于中国青海省内青藏高原的东北部，是中国最大的湖泊，也是中国最大的咸水湖、内流湖，早期面积4236.6平方公里，现因人为及气候因素而极遽减小，环湖周长360多公里。 &emsp;&emsp;驾车行驶在青海的公路上，不自觉就想到了一句歌词：“开车行驶在公路无际无边，有离开自己的感觉。”（《黄昏》——周传雄）青海的路真是太直了，向前方看去，总会有种天圆地方的感受。公路的两侧多为草甸，当然时不时也会从山峦间侧身而过。草甸大都因为过度放牧有些开始退化，亮绿之中夹杂着些许的暗黄。这种道路比较考验司机，若不是仪表盘上的数据，和窗外呼啸的风声，或许你还以为在原地踏步呢，长时间处于这种状态，疲劳在所难免。所以这里给想要去青海湖自驾的朋友们一个建议：团队中最好至少有两个司机。 &emsp;&emsp;二郎剑景区的门票太贵，饼干在网上搜索后，我们决定从一个叫做青海湖渔场的地方进去，给了藏民80块（Ps. 后来我们发现，不用从渔场进，也不用进景区，继续向前开有可以到湖边的路，而且没有人收费）。 &emsp;&emsp;宽广的湖面，没有太过炫目的阳光，有的是清明澄澈的浪声和徐徐的风。这一刻，多想就这样躺在湖边，倾听那悦耳的浪声，感受那轻柔的微风。只是，理想总是很丰满而现实却很骨感，一大波人突然涌现在这宁静的湖边，打破了这一份难得的静谧，这让刚想要在地上舒展身体的我感受到了一丝丝的失落。 &emsp;&emsp;在这湖边许下一个愿望吧，愿它乘着这高原上的风，缓缓上升，带着纯净的关心，拖着浓浓的想念，飘向远方，飘到你所牵挂，你所记挂的人的心中，未那人分担些许忧愁，为那人带去一丝安慰。 我猜饼干幻想开了演唱会，在向观众挥手鱼哥带上墨镜还是挺有大哥气息的嗯，我不会告诉你们怎么上去的，也不会给你们看他们抓拍我使劲向上爬的时候脸上狰狞的表情的上去虽然没形象了点，但是坐在上面还是挺爽的一种当大哥的感觉要不是拿着相机在拍照，我肯定过去推一把吓吓她 失望茶卡盐湖&emsp;&emsp;按照既定的计划，茶卡盐湖是今天的最后一站，风尘仆仆的赶到茶卡盐湖，停车场的冷清让我有点不敢相信，走到售票处，真想大喊一声congratulation，五点就停止售票了，而现在已经七点多了。面对空无一人的售票处有些泪奔。 空无一人的售票处＋全程唯一一张没戴墨镜的照片虽然没看到茶卡盐湖有些失望，但是也不能妨碍单反流氓拍照的脚步这次出行忘带三脚架了，手持相机拍耶稣光👼有些难度，就只有这样凑活着看吧 露宿黑马河&emsp;&emsp;无奈之下，只好驱车回到黑马河，是否再去茶卡盐湖视第二天天气而定。下高速没多久，在路牌标示“黑马河”的左侧，有一个叫做“星旅自驾游营地”的地方。这里晚上有警卫值班，对于不熟悉环境的人来说是一个不错的选择。 &emsp;&emsp;帐篷扎好不多时，零星的小雨变成了泼水，闪电也按捺不足开始舞动起来，一会儿雷声又带着沉闷的音调宣告着它的存在。老板人很好，几次过来询问我们是否需要帮助。她打着一把小伞冒雨过来，狂风将伞吹得左摇右晃，好似浪头的小船一般随时都可能倾覆，双手鼓起的青筋显示着她现在的吃力。饼干在他的感受中写到，让我们想护送她回去才不会觉得有愧于婉拒老板的盛情。 &emsp;&emsp;今天晚上的大餐——烧烤！说到这儿，不得不提一句，高原上把碳引燃真不是一件容易的事情，想我在海拔低一些的地方十分钟就搞定的事情，在这儿半个小时都没弄好，最后还只能麻烦老板弄了一点篝火剩下的碳给我们，不然的话就只能饿肚子啦！这里给饼干大兄弟道个歉，上图中他头顶上的一湾雨水全部被我倾泻在他身上了。 D4:达布逊淖尔之行日升黑马河 &emsp;&emsp;伴着凌晨的些许微光早早的起床了，为的当然是看日出，顺便，也看了看凌晨四点多的黑马河。害怕湖边堵车而选择了步行，到后来才发现担心是多余的。到湖边的时候那里已经密密麻麻站满了人，长枪短炮的严正以待，托着相机的我当时就乐了，终于不只我一个流氓了。 &emsp;&emsp;太阳的光辉将天边，将云端勾勒出丝丝的金晕，给人暖暖的感受，和和煦。而湖面这时候看上去十分的冷，大概只有野鸭们（姑且认为是吧，相隔太远看不真切）能享受这种湖水吧。它们在湖面上划过，在身后抛下柔和的涟漪，但是很快就被这广阔的，能包容一切的湖面所吞噬掉了。 &emsp;&emsp;虽然昨晚下了一场暴雨，但今早的云层依然是很厚，加之地处高原，云层就像要扑在大地上了一般，压得我有些喘不过气来，胸腔中有些憋闷，好像放了一块大石头压在上面一样。云啊，你能遮住初生之阳，可终究是挡不住新日之辉的。 &emsp;&emsp;新日的热量并不像正午那样猛烈，暖暖的直接流淌近你的心中，由内而外，带走几点的寒意，驱赶心中深藏的失落，脸上不自觉便挂上了笑容。从太阳的位置往岸上看，每一个人的嘴角都微微翘起，睫毛也带上了些许的弧线。想必太阳此刻很是高兴吧，岸上的人都在望着他笑，这一切都是他的功劳，他用自己辐射出的能量温暖了人们的内心。在这舒适的氛围中，你不会想仰天长啸，而只会带着笑容，沐浴在新日带来的暖意中，静静享受。所有的不快，所有的失望，所有的忧愁，在这一刻都消失得无影无踪了。 &emsp;&emsp;太阳一步步的爬高，也释放出更多的光和热，慢慢的，没有人敢直视他了。大家都低下了头，带着幸福和满足的微笑，血管中流淌着刚被烘得更暖的血液，怀着一颗乐观开朗的心，准备开始新一天的生活。我想，这也是为什么很多人都爱日出吧。少顷，太阳又挂得高了一些，这时候人们也渐渐散去了，离开了这带给他们力量的湖畔。 我们来了，达布逊淖尔！ &emsp;&emsp;茶卡盐湖也叫茶卡或达布逊淖尔，“茶卡”是藏语，意即盐池。“达布逊淖尔”是蒙古语，也是盐湖之意。今天的天气真是好得出奇，只需要打开镜头盖，肆意按下快门便是一张完美的风光照。 &emsp;&emsp;完美的天气，将昨日的抑郁一扫而空，乘着明媚的日光，在风儿的欢送中，车子欢快地飘到了茶卡盐湖景区。 伸手就能碰到天 小火车蛮有意思，唯一可惜的就是燃料是汽油据说这是盐雕假若由你驾驶这么一列火车，你会选择和谁共赴远方 鱼哥夺走了我手中的相机，抢着为我们拍照 由于忙于去中科院参加研修班以及后来项目结题，这之后的内容是我在7月18日续写的。由于相隔时间较长，有些细节可能不是描绘的很清晰。 &emsp;&emsp;茶卡盐湖是一面柔和的镜子，她折射出天空，折射出人影，也折射出你的心境。提到盐湖，自然又让我想起了西藏的纳木错，那片洁净得没有丝毫杂志的天湖。纳木错的海拔高达四千七百多米，有牧民说纳木错海拔很高像位于空中一般，所以称之为天湖。茶卡盐湖相对来说温柔一些，海拔只有三千米出头。 &emsp;&emsp;茶卡盐湖又被称为“天空之镜”，漫步于盐湖之中，仿佛行走于天空之上。回到北京，回到寝室，室友看着照片对我说，你们这是在拍电影吧，怎么在水面上走。对此我哈哈一笑，其实盐湖的水，就连我的脚背都无法完全浸没。 &emsp;&emsp;走在盐湖的水面上，深怕就踩碎了这面无暇的镜子，但现实总是那么的残酷，无论你下脚多么轻柔，湖面上总会荡漾起那么一丝的涟漪。仿佛就像一心求静，但总是会有那么一些些杂念一般。 &emsp;&emsp;在湖面上静静的站立几分钟，待波纹的能量耗尽，人物的倒影渐渐清晰起来。湖面荡起涟漪的时候人物的倒影是看不清的，所以要拍出较好的照片，一定要等到涟漪散尽。那么重点来了：记得带拖鞋！记得带拖鞋！记得带拖鞋！ 至于为什么，因为盐湖的湖底是卤水结晶，硬邦邦的，加上晶体生长又不是那么均匀。大家看过“奔跑吧，兄弟”吧，里面大家面对指压板是什么表情大家直到吧，对，光脚就是那种感受。 &emsp;&emsp;化用鲁迅先生在《纪念刘和珍君》一文中的语句，那就是——真正的勇士敢于裸脚直面盐湖的盐粒。所以一定带上拖鞋！ &emsp;&emsp;对于茶卡盐湖我的了解不是很深，也没办法像前面写藏传佛教相关的东西那样给大家介绍一些文化背景，就是好给大家看一堆照片了。 与饼干来一张合照： 绅士饼干向您致敬： 小鱼开始了她的瑜伽：天公作美，按下快门就是风景 下面给大家介绍一种在盐湖中最为刺激的运动！跳起来，嗯，这样的照片感觉不错是吧，再来一个接着跳其实吧，宝宝心里苦啊，落地的瞬间与粗糙的盐粒亲密接触，别提有多爽了！就这feel倍儿爽😭 嗯，不能霸占屏幕太长时间，来看看饼干这货，装优雅（翻白眼）对，我就是MJ转世！饼干也来跳了一下，还要提醒大家的就是，落地后溅起的卤水会大量附着在衣物上，水分蒸发后就是一团团白斑了。来个武打片即视感：两个大男人占据的篇幅貌似有些长了，看看优雅的熊猫我这里熊猫的照片比较少，主要是饼干给她拍的，写这篇游记的时候照片还没有汇总。 玩得有些累了，来张合照准备走吧不要问我为什么我站的位置比他们靠前 穿过小火车的铁路到对面才发现另一边的卤水结晶度更好，虽然脚底板刚受了盐粒的洗礼，但我们仍是经不住美景的诱惑，又开始了作死这两个迫不及待开始摆造型，由于靠得比较近，我又不想拍人肉背景，于是就成了二人的合照： 这个位置倒是给熊猫拍了好几张 小鱼有些受不了粗糙的湖底，留在了比较近的地方接着小鱼开始讲故事，当然带上了肢体语言： 我这鞭腿后来被大家说成“断腿”再来一个侧踹 走咯&emsp;&emsp;在茶卡盐湖玩得超级开心，说她是我们这几天经历的最好的景区也不为过，为了在里面拍照，我们连午饭都没有吃，一直从早上玩到下午三点多才离开。我们没有选择坐小火车而是步行进去，不过后来听说盐湖深处的风景和外面有些不同，让我感到些许的遗憾。 &emsp;&emsp;拖着有些疲惫的身子来到停车场，天空骤然变得黑呼呼的，风也开始吼起来，刚走出景区，便开始下起大雨来。雨点大得有些吓人，打在车身上哐当直响，给我一种车子会被这大雨扯碎的错觉。 &emsp;&emsp;已然下午三点多了，再去祁连时间不免有些紧张，便决定今晚暂时在哈尔盖停留。 &emsp;&emsp;长时间的驾驶不免让我感到疲惫，还好有饼干能代替我的位置。天公作美，车上抓拍了一张青海湖的照片：蓝天、湖面还有帐篷。 &emsp;&emsp;接下来就要给大家讲个惊悚故事了——我终于体会到“女司机”的可怕。&emsp;&emsp;潘哥一坐到驾驶座上，就问我，哪个是油门哪个是刹车。心里咯噔一下，瞌睡瞬间跑没影儿了。然后起步的时候问我，是应该先松手刹还是先挂D挡。哎，最后我们三个人心惊胆战，终于注视着熊猫把车子发动起来了。 D5:宗穆玛釉玛旅途之末——绝美卓尔山&emsp;&emsp;简单洗漱后便告别了哈尔盖镇，对于这个地方来说，我们只是四个微不足道的匆匆过客。哈尔盖对我来说，也没留下太多的印象，毕竟在这里停留仅仅是为了落脚而已。倒是晚上留宿的地方的藏民给我的记忆倒是多一些，在来之前，别人给我说一定要小心别被藏民坑了。可是我到这地方后，发现大多人都是那么的纯朴。&emsp;&emsp;我们帐篷还没扎好，这些可爱的人就给我们送来了一壶热水还有电筒，我们吃完火锅后洗锅的洗洁精也是用的他们的咧。大概九点多，我们离开了这只留宿了一晚的地方，向着宗穆玛釉玛行驶而去。&emsp;&emsp;今天的云和昨天有些不同，大概是因为昨天下过雨的原因。昨天的云密密麻麻，挤在一起，厚厚的一层，让我感到有些难以喘息。今天的云稀疏了很多，点缀在没有一丝一毫杂质的蓝宝石之上，映衬着道路两旁茵茵的绿草，驱赶着人们心中的躁动。&emsp;&emsp;远处突然一团亮白的物体挤进了我的眼球，定睛一看才发想原来是一座雪峰，在太阳的光辉下散发着纯净而又圣洁的气息。我一下子感觉同时处在了三个季节之中——气温是春，阳光似夏，白雪如冬。&emsp;&emsp;身处于这般意境之中，也许是因为长时间开车有些疲劳，不禁玩心大起。泊车于路边，“流氓”又开始了工作。背着镜头跳有些困难，跳得早了些，在照片中也就练起了蛤蟆功：&emsp;&emsp;卓尔山属于丹霞地貌，由红色砂岩、砾岩组成。之前和饼干还估摸着去一趟张掖，由于时间的原因不得不放弃，不过有了宗穆玛釉玛一行倒也不是那么的遗憾。&emsp;&emsp;传说祁连县之所以山清水秀、牛羊肥壮、物产丰富，其原因是就在于她这位来自龙界的王后，因为藏族的传统观念中龙神是财富的主人和象征，守护着秘密的财富。传说宗姆玛釉玛原为一龙界公主，一次偶然的邂逅，使她深深爱上了守护这里的山神——英武非凡的的阿咪东素，甘愿冒犯天规，冲突冲冲阻碍，嫁给阿咪东素为妃，龙王夫妇虽然坚决反对他们成亲，但她还是选择留在人间，与阿咪东素隔河相望，不离不弃。当然她为此付出了代价，变成一座石山。即使这样，她也无怨无悔，因为她和恋人——阿咪东素终身相伴守护着祁连的秀美山川和物华。 卓尔山，那是一个会让人迷失的斑斓的世界 一脚踏进，它的葱茏灿烂，波澜壮阔便让我眼前一亮，心门顿开 那山，豪迈里透着玲珑，阳刚中蕴含着灵秀 那花，此起彼伏繁华若锦，恰似一幅调了色的画布 一条条动感漂亮的弧线，一款款绚丽生动的色彩，一层层地铺向我的心海 最铭心的是，泛着红润光芒的山体；翠绿欲滴的青稞；金子般亮泽的菜花 这几种浓烈的色彩美美地交错在一起，撑起了高原唯美的天境 于是，天地不再单一，高原不再寂寞 如此目光无法顾及，语言无法描绘，又会让人醉了心田的景 美到你不用称赞，只需站在她面前，仰望 由远而近，由近而远，我在这一片斑斓里穿行 看它特有的色彩和生命的张力在我眼前无限蔓延 看它用足够的高度和诗情画意，渲染着一场视觉的盛宴 我的心，就在这一片斑斓里，浅醉，迷失&emsp;&emsp;藏语称为”宗穆玛釉玛”，意为美丽的红润皇后。站在卓儿山顶视野极度开阔，四周没有任何遮拦，山对面是一山尽览四季景色的牛心山，左右两侧分别是拉洞峡和白杨沟风景区，背面是连绵起伏的祁连山，山脚下滔滔八宝河像一条白色的哈达环绕在县城周边。处处美景，宛如仙境，令人心旷神怡。&emsp;&emsp;卓尔山的美，让我不敢相信自己的眼睛，让同行的朋友们完全沉醉其中。我想，看了这些照片，恐怕又得有人说：你的照片是造假吧？呵呵，如果自己没有走到，又没有很好地开发自己的相机，还是不要轻易下结论的好。&emsp;&emsp;信不信由你，卓尔山的色彩，就是这样的浓艳而又和谐，在被誉为“大美”的青海风光中独树一帜，透着高原特有的秀丽。&emsp;&emsp;有人把八宝镇周围的风景，称为“高原上的瑞士”。瑞士我没有去过，只是在电影、图片里有所领略。我的感觉是，到了卓尔山，瑞士不去也就罢了。当然啦，如果真有机会，把两者做一次实地的考察比较，我也不反对。&emsp;&emsp;关于卓尔山的风土人情和历史沿革，实在没有时间去考究了。而对风光美的文字描述，在这些镜头面前，已然显得多余。卓尔山的大美之秀，还是让这些在绚丽的阳光下下拍摄的照片来说话吧。旁边就有牌子写着“严禁攀爬”，但是真是手痒了潘哥说头发再长些就成梅超风了，其实我倒是觉得这随风而动的秀发煞是美丽微微一下很倾城饼干在上山前叫我们穿上羽绒服，这时他也受不住阳光的炙烤，脱下了厚重的羽绒服虽然现在还不是植被最为繁茂的时节，但这奇特的地形还是有着别样的美&emsp;&emsp;到了这时，整个旅程基本上就算是结束了，由于第二天要赶回北京的火车，所以今晚还要赶到西宁市去。 归程&emsp;&emsp;这一部分其实我不怎么愿意写，一写就会感叹美好的时光总是会在不经意间就全部溜走。 &emsp;&emsp;在路上才终于知道不到300公里为什么百度地图却估计了将近6个小时，原因在于路上有些霸道的物种。&emsp;&emsp;诺，这是其中的一种。在我放过一头羊过去之后，悲剧的是所有羊都跑到路中央来了。可怕的是，它们好像早就习惯了喇叭声一般，对我疯狂鸣喇叭的行为不理不睬，当真是走自己的路，让别人无路可走。&emsp;&emsp;牛大爷表现也是相当的淡定，不时听到它们哞哞的叫两声，好像在给你说，催什么催，我这不正在走么。一开始碰到它们还相当新奇，潘哥也大喊着“羊子羊子，拿来烫火锅”，可到后来不免有些厌倦。 &emsp;&emsp;从卓尔山回西宁不可避免的经过了门源，奈何我们没有足够的时间在这里停留，趁着换司机的功夫拍了一两张照片作为留念。&emsp;&emsp;晚上十点多终于赶到了青旅，旅程也就只剩下回北京的火车了。 D6:回首都了End.]]></content>
    </entry>

    
  
  
</search>
